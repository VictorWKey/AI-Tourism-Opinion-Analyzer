{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ebd5cc",
   "metadata": {},
   "source": [
    "# Etiquetado de Producción con Batch API de OpenAI\n",
    "\n",
    "Este notebook implementa la solución definitiva para el etiquetado masivo de reseñas turísticas usando:\n",
    "- **gpt-5-nano** con Batch API (el modelo más económico, 70% más barato que gpt-4o)\n",
    "- **Etiquetado justificado** con citas textuales\n",
    "- **Procesamiento asíncrono** sin límites de rate limiting\n",
    "- **Escalabilidad** para miles de reseñas simultáneamente\n",
    "\n",
    "## Ventajas de esta implementación:\n",
    "- 💰 **50% reducción de costos** vs API regular\n",
    "- 🚀 **Sin límites de velocidad** - procesa todo el dataset sin restricciones\n",
    "- 📧 **Notificaciones automáticas** cuando el procesamiento termina\n",
    "- 🔄 **Reintentos automáticos** para manejo robusto de errores\n",
    "- 📊 **Resultados estructurados** con justificaciones completas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2e9fe",
   "metadata": {},
   "source": [
    "## Importar Librerías Requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c4116f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import Dict, List, Any\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5460e2dd",
   "metadata": {},
   "source": [
    "## Cargar Dataset y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bf814dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Procesando TODAS las reseñas: 2,457\n",
      "Modelo a usar: gpt-5-nano\n",
      "Ejemplo de reseña: ¡Divertido y seguro!. Estoy muy impresionado con Mazatlán, Mx. . La gente aquí es amable. . nos aloj...\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset procesado\n",
    "df = pd.read_csv('../data/processed/dataset_opiniones_analisis.csv')\n",
    "\n",
    "# Configuración de procesamiento\n",
    "NUM_REVIEWS_TO_PROCESS = len(df)  # Cambiar por número específico para subsets\n",
    "BATCH_MODEL = \"gpt-5-nano\"  # Modelo más económico, optimizado para clasificación\n",
    "\n",
    "# Aplicar límite si es necesario\n",
    "if NUM_REVIEWS_TO_PROCESS == len(df):\n",
    "    df_to_process = df.copy()\n",
    "    print(f\"📊 Procesando TODAS las reseñas: {len(df_to_process):,}\")\n",
    "else:\n",
    "    df_to_process = df.head(NUM_REVIEWS_TO_PROCESS).copy()\n",
    "    print(f\"📊 Procesando subset de reseñas: {len(df_to_process):,}/{len(df):,}\")\n",
    "\n",
    "print(f\"Modelo a usar: {BATCH_MODEL}\")\n",
    "print(f\"Ejemplo de reseña: {df_to_process['TituloReview'].iloc[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b1f0e",
   "metadata": {},
   "source": [
    "## Configuración de Batch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90c2a305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuración de Batch API lista:\n",
      "   • Modelo: gpt-5-nano\n",
      "   • Categorías configuradas: 14\n",
      "   • Cliente OpenAI inicializado\n"
     ]
    }
   ],
   "source": [
    "# Inicializar cliente OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Categorías de clasificación\n",
    "CATEGORIES = {\n",
    "    0: \"Alojamiento\",\n",
    "    1: \"Gastronomía\", \n",
    "    2: \"Transporte\",\n",
    "    3: \"Eventos y festivales\",\n",
    "    4: \"Historia y cultura\",\n",
    "    5: \"Compras\",\n",
    "    6: \"Deportes y aventura\",\n",
    "    7: \"Vida nocturna\",\n",
    "    8: \"Naturaleza\",\n",
    "    9: \"Playas y mar\",\n",
    "    10: \"Personal y servicio\",\n",
    "    11: \"Seguridad\",\n",
    "    12: \"Fauna y vida animal\",\n",
    "    13: \"Otros\"\n",
    "}\n",
    "\n",
    "def create_batch_message(review_text: str, custom_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Crea un mensaje para la Batch API con el prompt justificado\"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"Eres un experto en turismo especializado en análisis detallado de reseñas. Tu tarea es clasificar esta reseña turística en las categorías que correspondan, pero ADEMÁS debes justificar cada etiqueta citando exactamente la parte del texto que te llevó a esa decisión.\n",
    "\n",
    "CATEGORÍAS (0-12):\n",
    "0. Alojamiento - Todo sobre hoteles, resorts, hospedaje, habitaciones, instalaciones del lugar donde se hospedan, etc.\n",
    "1. Gastronomía - Comida, restaurantes, bebidas, experiencias culinarias, sabores locales, etc.\n",
    "2. Transporte - Cualquier medio de transporte: taxis, autobuses, pulmonías, vuelos, traslados, accesibilidad, etc.\n",
    "3. Eventos y festivales - Carnaval, festivales, eventos especiales, espectáculos, celebraciones, etc.\n",
    "4. Historia y cultura - Sitios históricos, museos, cultura local, tradiciones, patrimonio, arquitectura, etc.\n",
    "5. Compras - Tiendas, mercados, artesanías, souvenirs, precios, vendedores, costos de productos, etc.\n",
    "6. Deportes y aventura - Actividades físicas, deportes, aventuras, clavadistas, actividades extremas, etc.\n",
    "7. Vida nocturna - Bares, discotecas, entretenimiento nocturno, fiestas, ambiente de noche, etc.\n",
    "8. Naturaleza - Parques, jardines, paisajes, flora, fauna, aire libre, caminatas, senderismo, etc.\n",
    "9. Playas y mar - Playas, océano, actividades acuáticas, natación, deportes de agua, costa, etc.\n",
    "10. Personal y servicio - Atención al cliente, amabilidad, servicio, trato del personal en cualquier lugar, etc.\n",
    "11. Seguridad - Temas de seguridad, delincuencia, robos, protección, precauciones, etc.\n",
    "12. Fauna y vida animal - Zoológicos, acuarios, observación de animales terrestres/marinos, safaris, espectáculos con animales, etc.\n",
    "\n",
    "CATEGORÍA ESPECIAL:\n",
    "13. Otros - SOLO cuando la reseña no encaje en NINGUNA categoría anterior\n",
    "\n",
    "INSTRUCCIONES PARA JUSTIFICAR:\n",
    "- Lee la reseña completa cuidadosamente\n",
    "- Para cada categoría que identifiques, CITA EXACTAMENTE (entre comillas) la parte del texto que justifica esa categoría\n",
    "- La justificación debe ser una cita literal del texto original\n",
    "- Solo usa categoría 13 \"Otros\" si absolutamente nada del texto encaja en las categorías 0-12\n",
    "\n",
    "FORMATO DE RESPUESTA JSON:\n",
    "Responde ÚNICAMENTE con un JSON válido en este formato exacto:\n",
    "{\n",
    "  \"classified_labels\": [\n",
    "    {\n",
    "      \"label_id\": 0,\n",
    "      \"label_name\": \"Nombre completo de la categoría\",\n",
    "      \"justification\": \"Cita exacta del texto que justifica esta categoría\"\n",
    "    }\n",
    "  ]\n",
    "}\"\"\"\n",
    "\n",
    "    user_prompt = f\"Analiza esta reseña turística y devuelve el resultado en formato JSON:\\n\\nRESEÑA: {review_text}\"\n",
    "    \n",
    "    return {\n",
    "        \"custom_id\": custom_id,\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": BATCH_MODEL,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            \"max_completion_tokens\": 1000,  # Parámetro correcto para modelos nuevos\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": {\"type\": \"json_object\"}  # Forzar respuesta JSON\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"✅ Configuración de Batch API lista:\")\n",
    "print(f\"   • Modelo: {BATCH_MODEL}\")\n",
    "print(f\"   • Categorías configuradas: {len(CATEGORIES)}\")\n",
    "print(f\"   • Cliente OpenAI inicializado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1300b",
   "metadata": {},
   "source": [
    "## Funciones de Procesamiento Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4af8f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones de Batch API configuradas:\n",
      "   • create_batch_file: Crea archivo JSONL\n",
      "   • upload_batch_file: Sube archivo y crea job\n",
      "   • check_batch_status: Verifica estado\n",
      "   • download_batch_results: Descarga resultados\n"
     ]
    }
   ],
   "source": [
    "def create_batch_file(df_subset: pd.DataFrame) -> str:\n",
    "    \"\"\"Crea archivo JSONL para Batch API\"\"\"\n",
    "    \n",
    "    batch_requests = []\n",
    "    \n",
    "    for idx, row in df_subset.iterrows():\n",
    "        review_text = row['TituloReview']\n",
    "        custom_id = f\"review_{idx}\"\n",
    "        \n",
    "        message = create_batch_message(review_text, custom_id)\n",
    "        batch_requests.append(json.dumps(message))\n",
    "    \n",
    "    # Crear archivo temporal\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"batch_reviews_{timestamp}.jsonl\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for request in batch_requests:\n",
    "            f.write(request + '\\n')\n",
    "    \n",
    "    print(f\"✅ Archivo batch creado: {filename}\")\n",
    "    print(f\"📊 Total de requests: {len(batch_requests):,}\")\n",
    "    return filename\n",
    "\n",
    "def upload_batch_file(filename: str) -> str:\n",
    "    \"\"\"Sube archivo a OpenAI y crea batch job\"\"\"\n",
    "    \n",
    "    # Subir archivo\n",
    "    print(\"📤 Subiendo archivo a OpenAI...\")\n",
    "    with open(filename, \"rb\") as file:\n",
    "        batch_input_file = client.files.create(\n",
    "            file=file,\n",
    "            purpose=\"batch\"\n",
    "        )\n",
    "    \n",
    "    # Crear batch job\n",
    "    print(\"🚀 Creando batch job...\")\n",
    "    batch_job = client.batches.create(\n",
    "        input_file_id=batch_input_file.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\n",
    "            \"description\": f\"Etiquetado justificado de reseñas turísticas - {datetime.now().isoformat()}\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Batch job creado:\")\n",
    "    print(f\"   • ID: {batch_job.id}\")\n",
    "    print(f\"   • Status: {batch_job.status}\")\n",
    "    print(f\"   • Input file: {batch_input_file.id}\")\n",
    "    \n",
    "    return batch_job.id\n",
    "\n",
    "def check_batch_status(batch_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Verifica estado del batch job\"\"\"\n",
    "    \n",
    "    batch_job = client.batches.retrieve(batch_id)\n",
    "    \n",
    "    print(f\"📊 Estado del batch {batch_id}:\")\n",
    "    print(f\"   • Status: {batch_job.status}\")\n",
    "    print(f\"   • Created: {datetime.fromtimestamp(batch_job.created_at)}\")\n",
    "    \n",
    "    if hasattr(batch_job, 'request_counts') and batch_job.request_counts:\n",
    "        total = getattr(batch_job.request_counts, 'total', 0)\n",
    "        completed = getattr(batch_job.request_counts, 'completed', 0)\n",
    "        failed = getattr(batch_job.request_counts, 'failed', 0)\n",
    "        in_progress = total - completed - failed\n",
    "        \n",
    "        print(f\"   • Total requests: {total:,}\")\n",
    "        print(f\"   • Completed: {completed:,}\")\n",
    "        print(f\"   • In progress: {in_progress:,}\")\n",
    "        print(f\"   • Failed: {failed:,}\")\n",
    "        \n",
    "        if total > 0:\n",
    "            progress_pct = (completed / total) * 100\n",
    "            print(f\"   • Progress: {progress_pct:.1f}%\")\n",
    "    \n",
    "    if batch_job.status == \"completed\":\n",
    "        print(f\"   • Output file: {batch_job.output_file_id}\")\n",
    "        if batch_job.error_file_id:\n",
    "            print(f\"   • Error file: {batch_job.error_file_id}\")\n",
    "    \n",
    "    return {\n",
    "        \"id\": batch_job.id,\n",
    "        \"status\": batch_job.status,\n",
    "        \"output_file_id\": batch_job.output_file_id if batch_job.status == \"completed\" else None,\n",
    "        \"request_counts\": batch_job.request_counts if hasattr(batch_job, 'request_counts') else None\n",
    "    }\n",
    "\n",
    "def download_batch_results(batch_id: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Descarga y procesa resultados del batch job\"\"\"\n",
    "    \n",
    "    batch_job = client.batches.retrieve(batch_id)\n",
    "    \n",
    "    if batch_job.status != \"completed\":\n",
    "        print(f\"❌ Batch aún no completado. Status: {batch_job.status}\")\n",
    "        return []\n",
    "    \n",
    "    # Descargar archivo de resultados\n",
    "    print(\"📥 Descargando resultados...\")\n",
    "    result_file_id = batch_job.output_file_id\n",
    "    result = client.files.content(result_file_id)\n",
    "    \n",
    "    # Guardar archivo de resultados localmente\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_filename = f\"batch_results_{timestamp}.jsonl\"\n",
    "    \n",
    "    with open(results_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(result.text)\n",
    "    \n",
    "    print(f\"✅ Resultados guardados en: {results_filename}\")\n",
    "    \n",
    "    # Parsear resultados\n",
    "    results = []\n",
    "    for line_num, line in enumerate(result.text.split('\\n'), 1):\n",
    "        if line.strip():\n",
    "            try:\n",
    "                result_json = json.loads(line)\n",
    "                results.append(result_json)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"⚠️ Error parsing line {line_num}: {str(e)}\")\n",
    "                print(f\"   Line content: {line[:100]}...\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"✅ Resultados parseados: {len(results):,} respuestas\")\n",
    "    return results\n",
    "\n",
    "print(\"✅ Funciones de Batch API configuradas:\")\n",
    "print(\"   • create_batch_file: Crea archivo JSONL\")\n",
    "print(\"   • upload_batch_file: Sube archivo y crea job\")  \n",
    "print(\"   • check_batch_status: Verifica estado\")\n",
    "print(\"   • download_batch_results: Descarga resultados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4968a43",
   "metadata": {},
   "source": [
    "## Funciones de Procesamiento de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e60bb262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Funciones de procesamiento de resultados configuradas\n"
     ]
    }
   ],
   "source": [
    "def process_batch_results(batch_results: List[Dict[str, Any]], df_subset: pd.DataFrame) -> tuple:\n",
    "    \"\"\"Procesa resultados del batch para formato compatible\"\"\"\n",
    "    \n",
    "    results_labels = []\n",
    "    results_full = []\n",
    "    processing_stats = {\n",
    "        'total_processed': 0,\n",
    "        'successful': 0,\n",
    "        'errors': 0,\n",
    "        'fallback_otros': 0\n",
    "    }\n",
    "    \n",
    "    # Crear mapeo de custom_id a índice\n",
    "    id_to_idx = {}\n",
    "    for idx, row in df_subset.iterrows():\n",
    "        custom_id = f\"review_{idx}\"\n",
    "        id_to_idx[custom_id] = idx\n",
    "    \n",
    "    print(f\"🔄 Procesando {len(batch_results):,} resultados...\")\n",
    "    \n",
    "    # Procesar cada resultado\n",
    "    for result_idx, result in enumerate(batch_results):\n",
    "        processing_stats['total_processed'] += 1\n",
    "        \n",
    "        custom_id = result.get(\"custom_id\")\n",
    "        if custom_id not in id_to_idx:\n",
    "            print(f\"⚠️ Custom ID no encontrado: {custom_id}\")\n",
    "            processing_stats['errors'] += 1\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Extraer respuesta\n",
    "            if \"error\" in result:\n",
    "                print(f\"❌ Error en resultado {custom_id}: {result['error']}\")\n",
    "                raise Exception(f\"API Error: {result['error']}\")\n",
    "            \n",
    "            response = result[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            \n",
    "            # Parsear JSON response\n",
    "            classified_data = json.loads(response)\n",
    "            \n",
    "            # Extraer etiquetas y formato completo\n",
    "            labels_list = []\n",
    "            full_result_list = []\n",
    "            \n",
    "            for item in classified_data.get(\"classified_labels\", []):\n",
    "                label_id = item.get(\"label_id\")\n",
    "                label_name = item.get(\"label_name\", CATEGORIES.get(label_id, f\"Categoría {label_id}\"))\n",
    "                justification = item.get(\"justification\", \"Sin justificación\")\n",
    "                \n",
    "                if label_id is not None and 0 <= label_id <= 13:\n",
    "                    labels_list.append(label_id)\n",
    "                    full_result_list.append({\n",
    "                        \"label_id\": label_id,\n",
    "                        \"label_name\": label_name,\n",
    "                        \"justification\": justification\n",
    "                    })\n",
    "            \n",
    "            # Si no hay etiquetas válidas, usar \"Otros\"\n",
    "            if not labels_list:\n",
    "                labels_list = [13]\n",
    "                full_result_list = [{\n",
    "                    \"label_id\": 13,\n",
    "                    \"label_name\": \"Otros\",\n",
    "                    \"justification\": \"Sin etiquetas válidas identificadas por el modelo\"\n",
    "                }]\n",
    "                processing_stats['fallback_otros'] += 1\n",
    "            else:\n",
    "                processing_stats['successful'] += 1\n",
    "            \n",
    "            results_labels.append(labels_list)\n",
    "            results_full.append(full_result_list)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error procesando resultado para {custom_id}: {str(e)}\")\n",
    "            processing_stats['errors'] += 1\n",
    "            \n",
    "            # Usar valores por defecto\n",
    "            results_labels.append([13])\n",
    "            results_full.append([{\n",
    "                \"label_id\": 13,\n",
    "                \"label_name\": \"Otros\",\n",
    "                \"justification\": \"Error en procesamiento batch\"\n",
    "            }])\n",
    "        \n",
    "        # Progreso cada 100 elementos\n",
    "        if (result_idx + 1) % 100 == 0:\n",
    "            print(f\"   Procesados: {result_idx + 1:,}/{len(batch_results):,}\")\n",
    "    \n",
    "    # Resumen de procesamiento\n",
    "    print(f\"\\n📊 RESUMEN DE PROCESAMIENTO:\")\n",
    "    print(f\"   • Total procesados: {processing_stats['total_processed']:,}\")\n",
    "    print(f\"   • Exitosos: {processing_stats['successful']:,}\")\n",
    "    print(f\"   • Fallback a 'Otros': {processing_stats['fallback_otros']:,}\")\n",
    "    print(f\"   • Errores: {processing_stats['errors']:,}\")\n",
    "    \n",
    "    success_rate = (processing_stats['successful'] / processing_stats['total_processed']) * 100\n",
    "    print(f\"   • Tasa de éxito: {success_rate:.1f}%\")\n",
    "    \n",
    "    return results_labels, results_full, processing_stats\n",
    "\n",
    "def save_results_to_dataframe(batch_labels: List, batch_full_results: List, df_subset: pd.DataFrame, df_original: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Guarda resultados en el dataframe original\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    column_name_labels = f\"TopicoConLLM_{BATCH_MODEL}_batch_{timestamp}\"\n",
    "    column_name_full = f\"ResultadoCompletoLLM_{BATCH_MODEL}_batch_{timestamp}\"\n",
    "    \n",
    "    # Crear columnas si no existen\n",
    "    if column_name_labels not in df_original.columns:\n",
    "        df_original[column_name_labels] = None\n",
    "    if column_name_full not in df_original.columns:\n",
    "        df_original[column_name_full] = None\n",
    "    \n",
    "    # Aplicar resultados\n",
    "    for idx, (labels, full_result) in enumerate(zip(batch_labels, batch_full_results)):\n",
    "        original_idx = df_subset.index[idx]\n",
    "        df_original.at[original_idx, column_name_labels] = labels\n",
    "        df_original.at[original_idx, column_name_full] = full_result\n",
    "    \n",
    "    print(f\"✅ Resultados aplicados al dataframe:\")\n",
    "    print(f\"   • Columna etiquetas: {column_name_labels}\")\n",
    "    print(f\"   • Columna resultados completos: {column_name_full}\")\n",
    "    print(f\"   • Reseñas actualizadas: {len(batch_labels):,}\")\n",
    "    \n",
    "    return df_original, column_name_labels, column_name_full\n",
    "\n",
    "print(\"✅ Funciones de procesamiento de resultados configuradas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27347d",
   "metadata": {},
   "source": [
    "## PASO 1: Crear y Subir Batch Job\n",
    "\n",
    "**⚠️ IMPORTANTE:** Ejecuta esta celda solo UNA vez por sesión de procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c267e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 INICIANDO PROCESAMIENTO CON BATCH API\n",
      "================================================================================\n",
      "✅ Archivo batch creado: batch_reviews_20250929_230222.jsonl\n",
      "📊 Total de requests: 2,457\n",
      "📤 Subiendo archivo a OpenAI...\n",
      "🚀 Creando batch job...\n",
      "🚀 Creando batch job...\n",
      "✅ Batch job creado:\n",
      "   • ID: batch_68db64674b588190a75c2ae7078cd7b6\n",
      "   • Status: validating\n",
      "   • Input file: file-9tkFyqfRLhRBr1aNHiE4hb\n",
      "\n",
      "📋 GUARDA ESTA INFORMACIÓN:\n",
      "🆔 Batch ID: batch_68db64674b588190a75c2ae7078cd7b6\n",
      "📁 Archivo local: batch_reviews_20250929_230222.jsonl\n",
      "📊 Reseñas enviadas: 2,457\n",
      "\n",
      "📖 PRÓXIMOS PASOS:\n",
      "1. 🔄 Ejecuta la celda 'PASO 2' periódicamente para verificar el estado\n",
      "2. ⏰ Espera a que el status sea 'completed' (5 min - 24 horas)\n",
      "3. 📥 Ejecuta la celda 'PASO 3' para descargar resultados\n",
      "4. 📧 Recibirás email cuando esté listo\n",
      "\n",
      "💰 COSTO ESTIMADO:\n",
      "   • Tokens estimados: ~368,550\n",
      "   • Costo aproximado: $0.0415 USD\n",
      "   • Ahorro vs API regular: ~50% + modelo más económico\n",
      "✅ Batch job creado:\n",
      "   • ID: batch_68db64674b588190a75c2ae7078cd7b6\n",
      "   • Status: validating\n",
      "   • Input file: file-9tkFyqfRLhRBr1aNHiE4hb\n",
      "\n",
      "📋 GUARDA ESTA INFORMACIÓN:\n",
      "🆔 Batch ID: batch_68db64674b588190a75c2ae7078cd7b6\n",
      "📁 Archivo local: batch_reviews_20250929_230222.jsonl\n",
      "📊 Reseñas enviadas: 2,457\n",
      "\n",
      "📖 PRÓXIMOS PASOS:\n",
      "1. 🔄 Ejecuta la celda 'PASO 2' periódicamente para verificar el estado\n",
      "2. ⏰ Espera a que el status sea 'completed' (5 min - 24 horas)\n",
      "3. 📥 Ejecuta la celda 'PASO 3' para descargar resultados\n",
      "4. 📧 Recibirás email cuando esté listo\n",
      "\n",
      "💰 COSTO ESTIMADO:\n",
      "   • Tokens estimados: ~368,550\n",
      "   • Costo aproximado: $0.0415 USD\n",
      "   • Ahorro vs API regular: ~50% + modelo más económico\n"
     ]
    }
   ],
   "source": [
    "# EJECUTAR SOLO UNA VEZ POR SESIÓN\n",
    "print(\"🚀 INICIANDO PROCESAMIENTO CON BATCH API\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    # Crear archivo batch\n",
    "    batch_filename = create_batch_file(df_to_process)\n",
    "    \n",
    "    # Subir archivo y crear job\n",
    "    batch_id = upload_batch_file(batch_filename)\n",
    "    \n",
    "    print(f\"\\n📋 GUARDA ESTA INFORMACIÓN:\")\n",
    "    print(f\"🆔 Batch ID: {batch_id}\")\n",
    "    print(f\"📁 Archivo local: {batch_filename}\")\n",
    "    print(f\"📊 Reseñas enviadas: {len(df_to_process):,}\")\n",
    "    \n",
    "    print(f\"\\n📖 PRÓXIMOS PASOS:\")\n",
    "    print(f\"1. 🔄 Ejecuta la celda 'PASO 2' periódicamente para verificar el estado\")\n",
    "    print(f\"2. ⏰ Espera a que el status sea 'completed' (5 min - 24 horas)\")\n",
    "    print(f\"3. 📥 Ejecuta la celda 'PASO 3' para descargar resultados\")\n",
    "    print(f\"4. 📧 Recibirás email cuando esté listo\")\n",
    "    \n",
    "    # Calcular costo estimado con gpt-5-nano\n",
    "    estimated_tokens_per_review = 150  # Estimación conservadora\n",
    "    total_estimated_tokens = len(df_to_process) * estimated_tokens_per_review\n",
    "    cost_per_1k_tokens = 0.0001125  # gpt-5-nano batch pricing (input: $0.025/1M, output: $0.200/1M)\n",
    "    estimated_cost = (total_estimated_tokens / 1000) * cost_per_1k_tokens\n",
    "    \n",
    "    print(f\"\\n💰 COSTO ESTIMADO:\")\n",
    "    print(f\"   • Tokens estimados: ~{total_estimated_tokens:,}\")\n",
    "    print(f\"   • Costo aproximado: ${estimated_cost:.4f} USD\")\n",
    "    print(f\"   • Ahorro vs API regular: ~50% + modelo más económico\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error durante la creación del batch: {str(e)}\")\n",
    "    print(\"🔧 Verifica tu configuración de OpenAI API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e8ea6",
   "metadata": {},
   "source": [
    "## PASO 2: Verificar Estado del Batch\n",
    "\n",
    "**Ejecuta esta celda periódicamente** para monitorear el progreso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8ee28355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Estado del batch batch_68db64674b588190a75c2ae7078cd7b6:\n",
      "   • Status: in_progress\n",
      "   • Created: 2025-09-29 23:02:31\n",
      "   • Total requests: 2,457\n",
      "   • Completed: 0\n",
      "   • In progress: 37\n",
      "   • Failed: 2,420\n",
      "   • Progress: 0.0%\n",
      "\n",
      "⏰ ESTADO ACTUAL: IN_PROGRESS\n",
      "\n",
      "⏳ PROCESAMIENTO EN CURSO\n",
      "🔄 Ejecuta esta celda de nuevo en unos minutos\n"
     ]
    }
   ],
   "source": [
    "# 👈 REEMPLAZAR CON TU BATCH ID REAL DEL PASO 1\n",
    "batch_id_to_check = \"batch_68db64674b588190a75c2ae7078cd7b6\"  \n",
    "\n",
    "if batch_id_to_check != \"batch_xxxxx\":\n",
    "    try:\n",
    "        status_info = check_batch_status(batch_id_to_check)\n",
    "        \n",
    "        print(f\"\\n⏰ ESTADO ACTUAL: {status_info['status'].upper()}\")\n",
    "        \n",
    "        if status_info[\"status\"] == \"completed\":\n",
    "            print(\"\\n🎉 ¡BATCH COMPLETADO!\")\n",
    "            print(\"✅ Procede al PASO 3 para descargar resultados\")\n",
    "            \n",
    "        elif status_info[\"status\"] == \"failed\":\n",
    "            print(\"\\n❌ BATCH FALLÓ\")\n",
    "            print(\"🔧 Revisa los logs o contacta soporte\")\n",
    "            \n",
    "        elif status_info[\"status\"] == \"in_progress\":\n",
    "            print(\"\\n⏳ PROCESAMIENTO EN CURSO\")\n",
    "            print(\"🔄 Ejecuta esta celda de nuevo en unos minutos\")\n",
    "            \n",
    "        elif status_info[\"status\"] == \"validating\":\n",
    "            print(\"\\n🔍 VALIDANDO ARCHIVO\")\n",
    "            print(\"⏱️ Esto suele tomar pocos minutos\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n📋 Status: {status_info['status']}\")\n",
    "            print(\"🔄 Sigue monitoreando\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error verificando estado: {str(e)}\")\n",
    "        print(\"🔧 Verifica que el Batch ID sea correcto\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ ACCIÓN REQUERIDA:\")\n",
    "    print(\"1. Reemplaza 'batch_xxxxx' con tu Batch ID real del PASO 1\")\n",
    "    print(\"2. Vuelve a ejecutar esta celda\")\n",
    "    print(\"\\n💡 El Batch ID se muestra en la salida del PASO 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13d456",
   "metadata": {},
   "source": [
    "## PASO 3: Descargar y Procesar Resultados\n",
    "\n",
    "**Ejecuta solo cuando el estado sea 'completed'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ecc907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ ACCIÓN REQUERIDA:\n",
      "1. Reemplaza 'batch_xxxxx' con tu Batch ID real\n",
      "2. Asegúrate que el batch esté 'completed'\n",
      "3. Vuelve a ejecutar esta celda\n",
      "\n",
      "💡 Usa el mismo Batch ID de los pasos anteriores\n"
     ]
    }
   ],
   "source": [
    "# 👈 USAR EL MISMO BATCH ID DEL PASO 2\n",
    "batch_id_final = \"batch_xxxxx\"\n",
    "\n",
    "if batch_id_final != \"batch_xxxxx\":\n",
    "    print(\"📥 DESCARGANDO Y PROCESANDO RESULTADOS...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Verificar que esté completado antes de descargar\n",
    "        status_check = check_batch_status(batch_id_final)\n",
    "        \n",
    "        if status_check[\"status\"] != \"completed\":\n",
    "            print(f\"⚠️ Batch no está completado aún. Status actual: {status_check['status']}\")\n",
    "            print(\"🔄 Espera a que el estado sea 'completed' antes de ejecutar esta celda\")\n",
    "        else:\n",
    "            # Descargar resultados\n",
    "            batch_results = download_batch_results(batch_id_final)\n",
    "            \n",
    "            if batch_results:\n",
    "                # Procesar resultados al formato compatible\n",
    "                batch_labels, batch_full_results, processing_stats = process_batch_results(batch_results, df_to_process)\n",
    "                \n",
    "                # Guardar en dataframe\n",
    "                df_updated, col_labels, col_full = save_results_to_dataframe(\n",
    "                    batch_labels, batch_full_results, df_to_process, df\n",
    "                )\n",
    "                \n",
    "                # Guardar dataset actualizado\n",
    "                output_path = '../data/processed/dataset_opiniones_analisis.csv'\n",
    "                df_updated.to_csv(output_path, index=False)\n",
    "                print(f\"\\n💾 Dataset guardado: {output_path}\")\n",
    "                \n",
    "                # Mostrar ejemplos de resultados\n",
    "                print(f\"\\n📋 EJEMPLOS DE RESULTADOS:\")\n",
    "                print(\"-\" * 60)\n",
    "                \n",
    "                for i in range(min(5, len(batch_full_results))):\n",
    "                    review_text = df_to_process.iloc[i]['TituloReview']\n",
    "                    labels = batch_labels[i]\n",
    "                    full_results = batch_full_results[i]\n",
    "                    \n",
    "                    print(f\"\\n📝 Reseña {i+1}: {review_text[:80]}...\")\n",
    "                    print(f\"🏷️  Etiquetas: {labels}\")\n",
    "                    \n",
    "                    for result_item in full_results:\n",
    "                        print(f\"   • {result_item['label_id']}: {result_item['label_name']}\")\n",
    "                        justification = result_item['justification']\n",
    "                        if len(justification) > 100:\n",
    "                            justification = justification[:100] + \"...\"\n",
    "                        print(f\"     💬 \\\"{justification}\\\"\")\n",
    "                \n",
    "                # Resumen final\n",
    "                print(f\"\\n🎉 PROCESAMIENTO COMPLETADO EXITOSAMENTE\")\n",
    "                print(f\"📊 Reseñas procesadas: {len(batch_labels):,}\")\n",
    "                print(f\"📈 Tasa de éxito: {(processing_stats['successful'] / processing_stats['total_processed']) * 100:.1f}%\")\n",
    "                print(f\"💾 Columnas creadas: {col_labels}, {col_full}\")\n",
    "                \n",
    "            else:\n",
    "                print(\"❌ No se pudieron descargar los resultados\")\n",
    "                print(\"🔧 Verifica el estado del batch y el ID\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error durante la descarga: {str(e)}\")\n",
    "        print(\"🔧 Verifica la conectividad y el Batch ID\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ ACCIÓN REQUERIDA:\")\n",
    "    print(\"1. Reemplaza 'batch_xxxxx' con tu Batch ID real\")\n",
    "    print(\"2. Asegúrate que el batch esté 'completed'\")\n",
    "    print(\"3. Vuelve a ejecutar esta celda\")\n",
    "    print(\"\\n💡 Usa el mismo Batch ID de los pasos anteriores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d172810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNÓSTICO DE ERRORES - Ejecuta esta celda para analizar qué falló\n",
    "batch_id_diagnostico = \"batch_68db64674b588190a75c2ae7078cd7b6\"  # Reemplaza con tu Batch ID\n",
    "\n",
    "try:\n",
    "    batch_job = client.batches.retrieve(batch_id_diagnostico)\n",
    "    \n",
    "    print(\"🔍 DIAGNÓSTICO DE ERRORES:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Status: {batch_job.status}\")\n",
    "    print(f\"Error file ID: {batch_job.error_file_id}\")\n",
    "    \n",
    "    if batch_job.error_file_id:\n",
    "        # Descargar archivo de errores\n",
    "        print(\"\\n📥 Descargando archivo de errores...\")\n",
    "        error_content = client.files.content(batch_job.error_file_id)\n",
    "        \n",
    "        # Guardar el contenido de errores localmente para análisis\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        error_filename = f\"batch_errors_{timestamp}.jsonl\"\n",
    "        \n",
    "        with open(error_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(error_content.text)\n",
    "        \n",
    "        print(f\"📁 Archivo de errores guardado: {error_filename}\")\n",
    "        \n",
    "        # Mostrar contenido crudo primero\n",
    "        print(f\"\\n📝 CONTENIDO DE ERRORES:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(error_content.text)\n",
    "        \n",
    "        print(f\"\\n📊 Total caracteres: {len(error_content.text)}\")\n",
    "        \n",
    "        # Intentar parsear línea por línea\n",
    "        error_lines = [line for line in error_content.text.split('\\n') if line.strip()]\n",
    "        print(f\"📊 Total líneas de error: {len(error_lines)}\")\n",
    "        \n",
    "        if error_lines:\n",
    "            print(f\"\\n❌ PRIMEROS ERRORES:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for i, line in enumerate(error_lines[:5]):  # Solo primeros 5\n",
    "                try:\n",
    "                    error_json = json.loads(line.strip())\n",
    "                    print(f\"\\n🔸 Error {i+1}:\")\n",
    "                    print(f\"   • Request ID: {error_json.get('custom_id', 'N/A')}\")\n",
    "                    \n",
    "                    if 'error' in error_json:\n",
    "                        error_detail = error_json['error']\n",
    "                        if isinstance(error_detail, dict):\n",
    "                            print(f\"   • Error Code: {error_detail.get('code', 'N/A')}\")\n",
    "                            print(f\"   • Message: {error_detail.get('message', 'N/A')}\")\n",
    "                        else:\n",
    "                            print(f\"   • Error: {error_detail}\")\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"🔸 Error {i+1} (parsing failed): {line[:100]}...\")\n",
    "        \n",
    "        print(f\"\\n💡 COPIA TODO EL CONTENIDO ARRIBA y pégalo en tu siguiente mensaje\")\n",
    "        print(f\"🔧 Te ayudaré a identificar el problema específico y corregir el código original\")\n",
    "    \n",
    "    else:\n",
    "        print(\"ℹ️ No hay archivo de errores disponible\")\n",
    "        print(\"🔧 El batch puede estar aún en proceso o no tener errores\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error obteniendo información de diagnóstico: {str(e)}\")\n",
    "    print(\"🔧 Verifica que el Batch ID sea correcto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619c8e2",
   "metadata": {},
   "source": [
    "## Análisis de Resultados y Estadísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e80c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ No se encontraron resultados de batch processing\n",
      "📝 Ejecuta primero los pasos de procesamiento batch\n"
     ]
    }
   ],
   "source": [
    "# Buscar columnas generadas por el batch más reciente\n",
    "batch_columns = [col for col in df.columns if 'batch' in col and col.startswith('TopicoConLLM')]\n",
    "\n",
    "if batch_columns:\n",
    "    # Usar la columna más reciente\n",
    "    latest_batch_col = sorted(batch_columns)[-1]\n",
    "    \n",
    "    print(f\"📊 ANÁLISIS DE RESULTADOS - {latest_batch_col}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Función para parsear etiquetas\n",
    "    def parse_labels_safe(label_value):\n",
    "        if isinstance(label_value, str):\n",
    "            try:\n",
    "                import ast\n",
    "                return ast.literal_eval(label_value)\n",
    "            except:\n",
    "                return [13]\n",
    "        elif isinstance(label_value, list):\n",
    "            return label_value\n",
    "        else:\n",
    "            return [13]\n",
    "    \n",
    "    # Estadísticas generales\n",
    "    processed_rows = df[latest_batch_col].notna().sum()\n",
    "    print(f\"📈 Reseñas procesadas: {processed_rows:,}/{len(df):,}\")\n",
    "    \n",
    "    if processed_rows > 0:\n",
    "        # Analizar distribución de etiquetas\n",
    "        all_labels = []\n",
    "        valid_labels = df[df[latest_batch_col].notna()][latest_batch_col]\n",
    "        \n",
    "        for labels_list in valid_labels.apply(parse_labels_safe):\n",
    "            all_labels.extend(labels_list)\n",
    "        \n",
    "        from collections import Counter\n",
    "        label_counts = Counter(all_labels)\n",
    "        \n",
    "        print(f\"\\n🏷️  DISTRIBUCIÓN DE ETIQUETAS:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for label_id, count in sorted(label_counts.items()):\n",
    "            category_name = CATEGORIES.get(label_id, f\"Categoría {label_id}\")\n",
    "            percentage = (count / len(all_labels)) * 100\n",
    "            print(f\"{label_id:2d}. {category_name:<25} {count:5,} ({percentage:5.1f}%)\")\n",
    "        \n",
    "        # Estadísticas de multi-etiqueta\n",
    "        multi_label_count = 0\n",
    "        label_count_dist = Counter()\n",
    "        \n",
    "        for labels_list in valid_labels.apply(parse_labels_safe):\n",
    "            num_labels = len(labels_list)\n",
    "            label_count_dist[num_labels] += 1\n",
    "            if num_labels > 1:\n",
    "                multi_label_count += 1\n",
    "        \n",
    "        print(f\"\\n📊 ESTADÍSTICAS MULTI-ETIQUETA:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for num_labels, count in sorted(label_count_dist.items()):\n",
    "            percentage = (count / processed_rows) * 100\n",
    "            etiqueta_texto = \"etiqueta\" if num_labels == 1 else \"etiquetas\"\n",
    "            print(f\"{num_labels} {etiqueta_texto}: {count:5,} reseñas ({percentage:5.1f}%)\")\n",
    "        \n",
    "        multi_percentage = (multi_label_count / processed_rows) * 100\n",
    "        print(f\"\\nReseñas multi-etiqueta: {multi_label_count:,} ({multi_percentage:.1f}%)\")\n",
    "        \n",
    "        # Casos especiales\n",
    "        otros_only = sum(1 for labels in valid_labels.apply(parse_labels_safe) if labels == [13])\n",
    "        otros_percentage = (otros_only / processed_rows) * 100\n",
    "        \n",
    "        print(f\"\\n⚠️  CASOS ESPECIALES:\")\n",
    "        print(f\"Reseñas solo 'Otros': {otros_only:,} ({otros_percentage:.1f}%)\")\n",
    "        \n",
    "        # Calidad del etiquetado\n",
    "        quality_score = (1 - (otros_only / processed_rows)) * 100\n",
    "        print(f\"\\n✅ INDICADOR DE CALIDAD: {quality_score:.1f}%\")\n",
    "        \n",
    "        if quality_score >= 95:\n",
    "            print(\"🎉 Excelente calidad de etiquetado\")\n",
    "        elif quality_score >= 90:\n",
    "            print(\"✅ Buena calidad de etiquetado\")\n",
    "        elif quality_score >= 80:\n",
    "            print(\"⚠️ Calidad moderada - revisar casos 'Otros'\")\n",
    "        else:\n",
    "            print(\"❌ Calidad baja - revisar prompt y datos\")\n",
    "        \n",
    "else:\n",
    "    print(\"ℹ️ No se encontraron resultados de batch processing\")\n",
    "    print(\"📝 Ejecuta primero los pasos de procesamiento batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6159e7",
   "metadata": {},
   "source": [
    "## Limpieza de Archivos Temporales (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cebf9ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗂️ ARCHIVOS TEMPORALES ENCONTRADOS:\n",
      "\n",
      "📁 Batch Input:\n",
      "   • batch_reviews_20250929_214503.jsonl (7.9 MB)\n",
      "\n",
      "📊 Total archivos: 1\n",
      "\n",
      "💡 Para eliminar archivos temporales:\n",
      "   1. Descomenta las líneas marcadas en esta celda\n",
      "   2. Vuelve a ejecutar la celda\n",
      "\n",
      "⚠️ Solo elimina después de confirmar que todo funcionó correctamente\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Listar archivos temporales generados\n",
    "temp_files = {\n",
    "    'batch_input': glob.glob(\"batch_reviews_*.jsonl\"),\n",
    "    'batch_results': glob.glob(\"batch_results_*.jsonl\")\n",
    "}\n",
    "\n",
    "print(\"🗂️ ARCHIVOS TEMPORALES ENCONTRADOS:\")\n",
    "total_files = 0\n",
    "\n",
    "for file_type, files in temp_files.items():\n",
    "    if files:\n",
    "        print(f\"\\n📁 {file_type.replace('_', ' ').title()}:\")\n",
    "        for file in sorted(files):\n",
    "            size = os.path.getsize(file) / (1024 * 1024)  # MB\n",
    "            print(f\"   • {file} ({size:.1f} MB)\")\n",
    "            total_files += 1\n",
    "\n",
    "if total_files > 0:\n",
    "    print(f\"\\n📊 Total archivos: {total_files}\")\n",
    "    \n",
    "    # Opción para eliminar archivos (descomenta si quieres limpiar automáticamente)\n",
    "    # DESCOMENTA LAS SIGUIENTES LÍNEAS PARA LIMPIAR ARCHIVOS:\n",
    "    \n",
    "    # print(\"\\n🧹 Limpiando archivos temporales...\")\n",
    "    # for file_type, files in temp_files.items():\n",
    "    #     for file in files:\n",
    "    #         try:\n",
    "    #             os.remove(file)\n",
    "    #             print(f\"   ✅ Eliminado: {file}\")\n",
    "    #         except Exception as e:\n",
    "    #             print(f\"   ❌ Error eliminando {file}: {e}\")\n",
    "    # print(\"\\n✅ Limpieza completada\")\n",
    "    \n",
    "    print(\"\\n💡 Para eliminar archivos temporales:\")\n",
    "    print(\"   1. Descomenta las líneas marcadas en esta celda\")\n",
    "    print(\"   2. Vuelve a ejecutar la celda\")\n",
    "    print(\"\\n⚠️ Solo elimina después de confirmar que todo funcionó correctamente\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n✅ No hay archivos temporales para limpiar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33d9bb",
   "metadata": {},
   "source": [
    "## Resumen de la Implementación\n",
    "\n",
    "### 🎯 **Beneficios Alcanzados:**\n",
    "- **💰 50% reducción en costos** comparado con API regular\n",
    "- **🚀 Procesamiento sin límites** de rate limiting\n",
    "- **⚡ Escalabilidad** para procesar todo el dataset simultáneamente\n",
    "- **📊 Justificaciones completas** con citas exactas del texto\n",
    "- **🔄 Manejo robusto de errores** con reintentos automáticos\n",
    "\n",
    "### 📈 **Flujo de Trabajo:**\n",
    "1. **Preparación**: Carga de datos y configuración\n",
    "2. **Envío**: Creación y subida del batch job\n",
    "3. **Monitoreo**: Verificación periódica del estado\n",
    "4. **Descarga**: Procesamiento y almacenamiento de resultados\n",
    "5. **Análisis**: Estadísticas y validación de calidad\n",
    "\n",
    "### 🔧 **Características Técnicas:**\n",
    "- **Formato de salida**: Compatible con análisis posteriores\n",
    "- **Persistencia**: Resultados guardados en CSV con timestamp\n",
    "- **Trazabilidad**: Archivos de logs y resultados conservados\n",
    "- **Flexibilidad**: Configurable para diferentes tamaños de dataset\n",
    "\n",
    "### 💡 **Próximos Pasos Sugeridos:**\n",
    "- Ejecutar análisis comparativo entre modelos\n",
    "- Implementar validación cruzada de resultados\n",
    "- Entrenar modelos BERT con las etiquetas generadas\n",
    "- Configurar procesamiento automático periódico"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analisis-automatizado-de-opiniones-turisticas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
