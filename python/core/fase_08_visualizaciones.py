"""  
Fase 08: GeneraciÃ³n de Visualizaciones
=======================================
Sistema inteligente y adaptativo de generaciÃ³n de visualizaciones profesionales.

Genera visualizaciones grÃ¡ficas puras organizadas en 7 secciones:
1. AnÃ¡lisis de Sentimientos (8 - donut, area, stacked bar, word clouds, etc.)
2. AnÃ¡lisis de Subjetividad (3 - donut, stacked bar, stacked area)
3. AnÃ¡lisis de CategorÃ­as (7 - bar, stacked bar, diverging bar, radar, heatmap, box plot, area)
4. AnÃ¡lisis JerÃ¡rquico de TÃ³picos (3 - bar charts, heatmap)
5. AnÃ¡lisis Temporal (4 - bar, line, trend, seasonality heatmap)
6. AnÃ¡lisis de Texto (4 - word cloud, histogram, bigrams, trigrams)
7. AnÃ¡lisis Cruzado (5 - heatmap, grouped bar, scatter, violin, stacked bar)

Los datos textuales (KPIs, resÃºmenes LLM, fortalezas/debilidades, validaciÃ³n)
se exportan a insights_textuales.json para ser mostrados en la UI por separado.

CaracterÃ­sticas:
- ðŸ§  Adaptativo: Valida volumen de datos antes de generar
- ðŸ“Š Solo grÃ¡ficos puros: Sin texto renderizado como imagen
- ðŸ’¾ Exporta a PNG de alta calidad (300 DPI)
- ðŸ“ Organiza por carpetas temÃ¡ticas
- ðŸ“‹ Exporta insights textuales a JSON
"""

import pandas as pd
import json
import shutil
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import warnings
from tqdm import tqdm
warnings.filterwarnings('ignore')

from .visualizaciones.validador import ValidadorVisualizaciones
from .visualizaciones.generador_sentimientos import GeneradorSentimientos
from .visualizaciones.generador_categorias import GeneradorCategorias
from .visualizaciones.generador_topicos import GeneradorTopicos
from .visualizaciones.generador_temporal import GeneradorTemporal
from .visualizaciones.generador_texto import GeneradorTexto
from .visualizaciones.generador_combinados import GeneradorCombinados
from .visualizaciones.generador_subjetividad import GeneradorSubjetividad
from .visualizaciones.exportador_insights import ExportadorInsights
from .visualizaciones.utils import configurar_estilo_grafico, configurar_tema


class GeneradorVisualizaciones:
    """
    Generador adaptativo de visualizaciones para anÃ¡lisis turÃ­stico.
    
    Valida el dataset y genera solo las visualizaciones viables segÃºn el volumen
    y caracterÃ­sticas de los datos disponibles.
    """
    
    def __init__(self, dataset_path=None, output_dir=None):
        """
        Inicializa el generador de visualizaciones.
        
        Args:
            dataset_path: Ruta al dataset CSV procesado (default: from ConfigDataset)
            output_dir: Directorio de salida para las visualizaciones (default: from ConfigDataset)
        """
        from config.config import ConfigDataset
        self.dataset_path = Path(dataset_path) if dataset_path else ConfigDataset.get_dataset_path()
        self.output_dir = Path(output_dir) if output_dir else ConfigDataset.get_visualizaciones_dir()
        self.df = None
        self.validador = None
        self.visualizaciones_generadas = []
        self.visualizaciones_omitidas = []
    
    def ya_procesado(self):
        """
        Verifica si esta fase ya fue ejecutada.
        Revisa si existen los directorios light/dark con archivos PNG.
        """
        light_dir = self.output_dir / 'light'
        dark_dir = self.output_dir / 'dark'
        return (
            light_dir.exists() and len(list(light_dir.rglob('*.png'))) > 0
            and dark_dir.exists() and len(list(dark_dir.rglob('*.png'))) > 0
        )
    
    def _limpiar_visualizaciones_previas(self):
        """
        Elimina todas las visualizaciones anteriores para evitar confusiÃ³n
        con resultados de datasets previos.
        """
        if self.output_dir.exists():
            print("\nðŸ§¹ Limpiando visualizaciones previas...")
            try:
                # Eliminar todo el contenido del directorio
                shutil.rmtree(self.output_dir)
                print("   âœ“ Visualizaciones previas eliminadas")
            except Exception as e:
                print(f"   âš ï¸  Error al limpiar visualizaciones: {e}")
        
        # Recrear el directorio limpio
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def procesar(self, forzar=False):
        """
        Pipeline principal de generaciÃ³n de visualizaciones.
        
        1. Carga y valida datos
        2. Configura estilo grÃ¡fico
        3. Crea estructura de carpetas
        4. Genera visualizaciones por secciÃ³n
        5. Genera reporte final
        
        Args:
            forzar: Si es True, ejecuta incluso si ya fue procesado
        """
        if not forzar and self.ya_procesado():
            print("   â­ï¸  Fase ya ejecutada previamente (omitiendo)")
            return
        print("\n" + "="*60)
        print("FASE 08: GENERACIÃ“N DE VISUALIZACIONES")
        print("="*60)
        
        # 0. Limpiar visualizaciones previas (importante para evitar confusiÃ³n con datasets anteriores)
        self._limpiar_visualizaciones_previas()
        
        # 1. Cargar datos
        self._cargar_datos()
        
        # 2. Validar dataset
        self._validar_dataset()
        
        # 3. Configurar estilo
        configurar_estilo_grafico()
        
        # 4. Crear estructura de carpetas
        self._crear_carpetas()
        
        # 5. Generar visualizaciones por secciÃ³n (light y dark)
        print("\nðŸ“Š Generando visualizaciones...")
        
        # Lista de secciones a generar (solo grÃ¡ficos puros)
        # Note: Dashboard section is deprecated and no longer generated
        secciones = [
            ('Sentimientos', GeneradorSentimientos),
            ('Subjetividad', GeneradorSubjetividad),
            ('CategorÃ­as', GeneradorCategorias),
            ('TÃ³picos', GeneradorTopicos),
            ('Temporal', GeneradorTemporal),
            ('Texto', GeneradorTexto),
            ('AnÃ¡lisis Cruzado', GeneradorCombinados),
        ]
        
        # Build a flat list of (theme, section_name, generator_class) for a single progress bar
        tareas = []
        for tema in ['light', 'dark']:
            for nombre, generador_class in secciones:
                tareas.append((tema, nombre, generador_class))
        
        tema_actual = None
        for tema, nombre, generador_class in tqdm(tareas, desc="   Progreso"):
            if tema != tema_actual:
                print(f"\nðŸŽ¨ Generando versiÃ³n [{tema}]...")
                configurar_tema(tema)
                configurar_estilo_grafico()
                tema_actual = tema
            tema_output_dir = self.output_dir / tema
            self._generar_seccion(nombre, generador_class, tema_output_dir)
        
        # Restaurar tema light como default
        configurar_tema('light')
        
        # 6. Exportar insights textuales a JSON (KPIs, resÃºmenes, fortalezas, etc.)
        self._exportar_insights()
        
        # 7. Generar reporte final (scans actual files on disk)
        self._generar_reporte_final()
        
        # Read back the report to show accurate counts
        reporte_path = self.output_dir / 'reporte_generacion.json'
        with open(reporte_path, 'r', encoding='utf-8') as f:
            reporte = json.load(f)
        actual_count = reporte['visualizaciones']['total_generadas']
        actual_omitidas = reporte['visualizaciones']['total_omitidas']
        
        print("\n" + "="*60)
        print("âœ… Visualizaciones generadas exitosamente")
        print(f"   â€¢ Total generadas: {actual_count} (Ã—2 temas: light + dark)")
        print(f"   â€¢ Total omitidas: {actual_omitidas}")
        print(f"   â€¢ VersiÃ³n light: {self.output_dir}/light/")
        print(f"   â€¢ VersiÃ³n dark:  {self.output_dir}/dark/")
        print(f"   â€¢ Insights textuales: {self.output_dir}/insights_textuales.json")
        print(f"   â€¢ Reporte: {self.output_dir}/reporte_generacion.json")
        print("="*60)
    
    def _cargar_datos(self):
        """Carga el dataset procesado."""
        if not self.dataset_path.exists():
            raise FileNotFoundError(
                f"Dataset no encontrado: {self.dataset_path}\n"
                "AsegÃºrate de ejecutar las Fases 01-07 primero."
            )
        
        self.df = pd.read_csv(self.dataset_path)
        print(f"\nðŸ“‚ Dataset cargado: {len(self.df)} opiniones")
    
    def _validar_dataset(self):
        """Valida el dataset y muestra resumen."""
        self.validador = ValidadorVisualizaciones(self.df)
        resumen = self.validador.get_resumen()
        
        print(f"\nðŸ” ValidaciÃ³n del dataset:")
        print(f"   â€¢ Total opiniones: {resumen['total_opiniones']}")
        print(f"   â€¢ Fechas vÃ¡lidas: {'âœ“' if resumen['tiene_fechas'] else 'âœ— (anÃ¡lisis temporal no disponible)'}")
        print(f"   â€¢ CalificaciÃ³n: {'âœ“' if resumen['tiene_calificacion'] else 'âœ— (generada por el modelo de sentimientos)'}")
        
        if resumen['tiene_fechas']:
            print(f"   â€¢ Rango temporal: {resumen['rango_temporal_dias']} dÃ­as")
        
        print(f"   â€¢ CategorÃ­as vÃ¡lidas: {resumen['categorias_validas']}")
        print(f"   â€¢ TÃ³picos detectados: {'âœ“' if resumen['tiene_topicos'] else 'âœ—'}")
        print(f"   â€¢ Sentimientos:")
        print(f"     - Positivo: {resumen['diversidad_sentimientos']['positivo']}")
        print(f"     - Neutro: {resumen['diversidad_sentimientos']['neutro']}")
        print(f"     - Negativo: {resumen['diversidad_sentimientos']['negativo']}")
    
    def _crear_carpetas(self):
        """Crea la estructura de carpetas para las visualizaciones (light y dark)."""
        carpetas = [
            '01_sentimientos',
            '02_subjetividad',
            '03_categorias',
            '04_topicos',
            '05_temporal',
            '06_texto',
            '07_combinados'
        ]
        
        for tema in ['light', 'dark']:
            tema_dir = self.output_dir / tema
            tema_dir.mkdir(parents=True, exist_ok=True)
            for carpeta in carpetas:
                (tema_dir / carpeta).mkdir(parents=True, exist_ok=True)
    
    def _generar_seccion(self, nombre: str, GeneradorClass, output_dir: Path = None):
        """
        Genera visualizaciones de una secciÃ³n especÃ­fica.
        
        Args:
            nombre: Nombre de la secciÃ³n
            GeneradorClass: Clase del generador especializado
            output_dir: Directorio de salida (si None, usa self.output_dir)
        """
        target_dir = output_dir or self.output_dir
        print(f"\n   [{nombre}] Generando visualizaciones...")
        
        try:
            generador = GeneradorClass(self.df, self.validador, target_dir)
            generadas = generador.generar_todas()
            
            self.visualizaciones_generadas.extend(generadas)
            
            print(f"   âœ“ {nombre}: {len(generadas)} visualizaciones generadas")
            
        except Exception as e:
            print(f"   âš ï¸  Error en {nombre}: {e}")
    
    def _exportar_insights(self):
        """Exporta insights textuales a JSON para la UI."""
        print("\n   [Insights] Exportando datos textuales...")
        try:
            exportador = ExportadorInsights(self.df, self.validador, self.output_dir)
            nombre = exportador.exportar()
            print(f"   âœ“ Insights textuales exportados: {nombre}")
        except Exception as e:
            print(f"   âš ï¸  Error exportando insights: {e}")

    def _generar_reporte_final(self):
        """Genera reporte JSON con resumen de la generaciÃ³n.
        
        Scans actual PNG files on disk (from the 'light' theme folder) to ensure
        the report matches exactly what the Dashboard UI sees.
        """
        resumen_validacion = self.validador.get_resumen()
        
        # Map section names to their folder names on disk
        seccion_carpetas = {
            'sentimientos': '01_sentimientos',
            'subjetividad': '02_subjetividad',
            'categorias':   '03_categorias',
            'topicos':      '04_topicos',
            'temporal':     '05_temporal',
            'texto':        '06_texto',
            'combinados':   '07_combinados',
        }
        
        # Scan actual files from disk (use 'light' theme as reference)
        light_dir = self.output_dir / 'light'
        por_seccion = {}
        lista_generadas = []
        
        for seccion, carpeta in seccion_carpetas.items():
            carpeta_path = light_dir / carpeta
            if carpeta_path.exists():
                pngs = sorted([f.stem for f in carpeta_path.glob('*.png')])
                por_seccion[seccion] = len(pngs)
                lista_generadas.extend(pngs)
            else:
                por_seccion[seccion] = 0
        
        total_generadas = len(lista_generadas)
        
        # Determine omitted: names that generators reported but have no file on disk
        nombres_reportados = set(dict.fromkeys(self.visualizaciones_generadas))
        nombres_en_disco = set(lista_generadas)
        omitidas_reales = sorted(nombres_reportados - nombres_en_disco)
        # Also include any explicitly tracked omissions
        omitidas_explicitas = list(dict.fromkeys(self.visualizaciones_omitidas))
        todas_omitidas = sorted(set(omitidas_reales) | set(omitidas_explicitas))
        
        reporte = {
            "fecha_generacion": datetime.now().isoformat(),
            "dataset": {
                "total_opiniones": int(resumen_validacion['total_opiniones']),
                "tiene_fechas": bool(resumen_validacion['tiene_fechas']),
                "tiene_calificacion": bool(resumen_validacion.get('tiene_calificacion', False)),
                "rango_temporal_dias": int(resumen_validacion['rango_temporal_dias']) if resumen_validacion['rango_temporal_dias'] is not None else 0,
                "categorias_identificadas": int(resumen_validacion['categorias_validas']),
                "cobertura_topicos": bool(resumen_validacion['tiene_topicos'])
            },
            "visualizaciones": {
                "total_generadas": total_generadas,
                "total_omitidas": len(todas_omitidas),
                "por_seccion": por_seccion,
                "lista_generadas": lista_generadas
            },
            "omitidas": todas_omitidas,
            "recomendaciones": self._generar_recomendaciones(resumen_validacion)
        }
        
        # Guardar reporte
        reporte_path = self.output_dir / 'reporte_generacion.json'
        with open(reporte_path, 'w', encoding='utf-8') as f:
            json.dump(reporte, f, ensure_ascii=False, indent=2)
    
    def _generar_recomendaciones(self, resumen: Dict) -> List[str]:
        """Genera recomendaciones basadas en el dataset."""
        recomendaciones = []
        
        if resumen['total_opiniones'] < 100:
            recomendaciones.append(
                "Dataset pequeÃ±o (<100 opiniones). Algunas visualizaciones avanzadas no fueron generadas. "
                "Considera agregar mÃ¡s datos para anÃ¡lisis mÃ¡s robustos."
            )
        
        if not resumen['tiene_fechas']:
            recomendaciones.append(
                "No hay fechas vÃ¡lidas en el dataset. El anÃ¡lisis temporal no estÃ¡ disponible. "
                "Incluir una columna 'FechaEstadia' con fechas habilitarÃ­a las visualizaciones temporales."
            )
        
        if not resumen.get('tiene_calificacion', False):
            recomendaciones.append(
                "La columna 'Calificacion' no estaba en el dataset original. "
                "Fue generada automÃ¡ticamente por el modelo de sentimientos (1-5 estrellas)."
            )
        
        if not resumen['tiene_topicos']:
            recomendaciones.append(
                "No se detectaron tÃ³picos en el dataset. El anÃ¡lisis jerÃ¡rquico estÃ¡ limitado. "
                "Ejecuta la Fase 06 para identificar tÃ³picos antes de generar visualizaciones."
            )
        
        if resumen['total_opiniones'] >= 100 and resumen['tiene_fechas'] and resumen['tiene_topicos']:
            recomendaciones.append(
                "âœ“ Dataset completo y robusto. Todas las visualizaciones principales fueron generadas exitosamente."
            )
        
        if resumen['categorias_validas'] < 5:
            recomendaciones.append(
                "Pocas categorÃ­as identificadas. Esto puede limitar la granularidad del anÃ¡lisis por categorÃ­a."
            )
        
        return recomendaciones
