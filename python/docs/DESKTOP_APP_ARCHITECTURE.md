# ğŸ–¥ï¸ AI Tourism Opinion Analyzer - Desktop Application Architecture & Technology Stack

## ğŸ“‹ Executive Summary

**Question:** Is it possible to create a desktop app that includes all current pipeline features with a user-friendly UI?

**Answer:** âœ… **Yes, it is absolutely feasible.** The current pipeline is well-structured and modular, making it an excellent candidate for a desktop application wrapper. Below is the comprehensive analysis and proposed architecture.

---

## ğŸ” Current Pipeline Analysis

### Pipeline Overview

The AI Tourism Opinion Analyzer is a 7-phase NLP pipeline for analyzing tourism opinions:

| Phase | Name | Technology | LLM Required |
|-------|------|------------|--------------|
| 01 | Basic Processing | Pandas | âŒ |
| 02 | Sentiment Analysis | HuggingFace BERT | âŒ |
| 03 | Subjectivity Analysis | Fine-tuned BERT | âŒ |
| 04 | Category Classification | Fine-tuned BERT Multi-label | âŒ |
| 05 | Hierarchical Topic Analysis | BERTopic + LLM | âœ… |
| 06 | Intelligent Summarization | LangChain + LLM | âœ… |
| 07 | Visualization Generation | Matplotlib/Plotly | âŒ |

### Current Dependencies

```
Core ML/NLP:
â”œâ”€â”€ torch >= 2.0.0 (Deep Learning)
â”œâ”€â”€ transformers >= 4.30.0 (HuggingFace models)
â”œâ”€â”€ sentence-transformers >= 2.2.0 (Embeddings)
â”œâ”€â”€ bertopic >= 0.16.0 (Topic modeling)
â”œâ”€â”€ nltk >= 3.8.0 (NLP utilities)

LLM Integration:
â”œâ”€â”€ langchain >= 0.1.0
â”œâ”€â”€ langchain-openai >= 0.0.5
â”œâ”€â”€ langchain-ollama >= 0.1.0

Visualization:
â”œâ”€â”€ matplotlib >= 3.7.0
â”œâ”€â”€ seaborn >= 0.12.0
â”œâ”€â”€ plotly >= 5.14.0
â”œâ”€â”€ wordcloud >= 1.9.0

Data Processing:
â”œâ”€â”€ pandas >= 2.0.0
â”œâ”€â”€ numpy >= 1.24.0
â”œâ”€â”€ scikit-learn >= 1.3.0
```

### Key Characteristics for Desktop App

| Characteristic | Assessment | Impact |
|---------------|------------|--------|
| **Modular Architecture** | âœ… Excellent | Easy to integrate with UI |
| **No Backend Required** | âœ… Confirmed | All local processing |
| **Configuration System** | âœ… Well-designed | Easy settings UI |
| **LLM Flexibility** | âœ… Local + API | User choice supported |
| **Output Formats** | âœ… JSON/CSV/PNG | Display-ready |
| **Progress Tracking** | âš ï¸ Limited | Needs enhancement for UI |

---

## ğŸ—ï¸ Proposed Technology Stack

### Primary Recommendation: Electron + Python Backend

Given your team's JavaScript experience and that app size is not a concern, **Electron** is the optimal choice.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ELECTRON APPLICATION                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚               RENDERER PROCESS (Frontend)            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚    React    â”‚ â”‚   Tailwind  â”‚ â”‚   Chart.js  â”‚   â”‚    â”‚
â”‚  â”‚  â”‚  + TypeScriptâ”‚ â”‚     CSS     â”‚ â”‚  / Recharts â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                 â”‚
â”‚                      IPC Bridge                              â”‚
â”‚                            â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                 MAIN PROCESS (Backend)               â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚   Node.js   â”‚ â”‚python-shell â”‚ â”‚  File Systemâ”‚   â”‚    â”‚
â”‚  â”‚  â”‚   Bridge    â”‚ â”‚   Manager   â”‚ â”‚   Access    â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PYTHON RUNTIME                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚        AI Tourism Opinion Analyzer Pipeline          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚ Phase 1 â”‚ â”‚ Phase 2 â”‚ â”‚   ...   â”‚ â”‚ Phase 7 â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â”‚                                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚   LLM Provider  â”‚ â”‚    BERT/Transformers   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚ (Ollama/OpenAI) â”‚ â”‚       Models           â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack Breakdown

#### Frontend (Renderer Process)

| Component | Technology | Justification |
|-----------|------------|---------------|
| **Framework** | React 18+ | Team JS experience, rich ecosystem |
| **Language** | TypeScript | Type safety, better DX |
| **Styling** | Tailwind CSS | Rapid UI development |
| **State Management** | Zustand | Simple, lightweight |
| **Charts** | Recharts + Plotly.js | Interactive visualizations |
| **Forms** | React Hook Form + Zod | Validation |
| **UI Components** | shadcn/ui | Modern, accessible |

#### Backend (Main Process)

| Component | Technology | Justification |
|-----------|------------|---------------|
| **Runtime** | Node.js 18+ | Electron core |
| **Python Bridge** | python-shell | Spawn Python processes |
| **IPC** | Electron IPC | Renderer â†” Main communication |
| **File System** | Node fs/path | Native file operations |
| **Storage** | electron-store | Persistent settings |

#### Python Integration

| Component | Technology | Justification |
|-----------|------------|---------------|
| **Bundling** | PyInstaller | Bundle Python runtime |
| **API Layer** | Custom JSON protocol | Structured communication |
| **Existing Code** | 100% reused | All 7 phases as-is |

#### Build & Distribution

| Component | Technology | Justification |
|-----------|------------|---------------|
| **Bundler** | Electron Forge | Official Electron toolchain |
| **Installer** | electron-builder | Cross-platform builds |
| **Auto-Update** | electron-updater | Optional updates |

---

## ğŸ“ Application Architecture

### High-Level Architecture

```
ai-tourism-analyzer-desktop/
â”œâ”€â”€ package.json                    # Node.js dependencies
â”œâ”€â”€ forge.config.ts                 # Electron Forge config
â”œâ”€â”€ tsconfig.json                   # TypeScript config
â”œâ”€â”€ tailwind.config.js              # Tailwind CSS config
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/                       # Electron Main Process
â”‚   â”‚   â”œâ”€â”€ index.ts                # Main entry point
â”‚   â”‚   â”œâ”€â”€ preload.ts              # Preload scripts
â”‚   â”‚   â”œâ”€â”€ ipc/                    # IPC handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline.ts         # Pipeline execution
â”‚   â”‚   â”‚   â”œâ”€â”€ files.ts            # File operations
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.ts         # App settings
â”‚   â”‚   â”‚   â””â”€â”€ ollama.ts           # Ollama management
â”‚   â”‚   â”œâ”€â”€ python/                 # Python bridge
â”‚   â”‚   â”‚   â”œâ”€â”€ bridge.ts           # Python process manager
â”‚   â”‚   â”‚   â”œâ”€â”€ executor.ts         # Command executor
â”‚   â”‚   â”‚   â””â”€â”€ protocol.ts         # JSON protocol
â”‚   â”‚   â””â”€â”€ utils/                  # Main process utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ renderer/                   # React Frontend
â”‚   â”‚   â”œâ”€â”€ App.tsx                 # Root component
â”‚   â”‚   â”œâ”€â”€ main.tsx                # Renderer entry
â”‚   â”‚   â”œâ”€â”€ index.html              # HTML template
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/             # UI Components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/                 # shadcn components
â”‚   â”‚   â”‚   â”œâ”€â”€ layout/             # Layout components
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ MainContent.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline/           # Pipeline UI
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PhaseCard.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PhaseProgress.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PhaseConfig.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ PipelineRunner.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ visualizations/     # Charts & graphs
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DashboardView.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SentimentCharts.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ CategoryCharts.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TopicCharts.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ TemporalCharts.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ data/               # Data management
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DatasetUploader.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DataPreview.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ExportOptions.tsx
â”‚   â”‚   â”‚   â””â”€â”€ settings/           # Settings UI
â”‚   â”‚   â”‚       â”œâ”€â”€ LLMSettings.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ OllamaManager.tsx
â”‚   â”‚   â”‚       â””â”€â”€ GeneralSettings.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/                  # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Pipeline.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Visualizations.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Results.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Settings.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ stores/                 # Zustand stores
â”‚   â”‚   â”‚   â”œâ”€â”€ pipelineStore.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ dataStore.ts
â”‚   â”‚   â”‚   â””â”€â”€ settingsStore.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ hooks/                  # Custom hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ usePipeline.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useIPC.ts
â”‚   â”‚   â”‚   â””â”€â”€ useOllama.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ lib/                    # Utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ ipc.ts              # IPC client
â”‚   â”‚   â”‚   â””â”€â”€ utils.ts            # General utilities
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â””â”€â”€ globals.css         # Global styles
â”‚   â”‚
â”‚   â””â”€â”€ shared/                     # Shared types
â”‚       â”œâ”€â”€ types.ts                # TypeScript types
â”‚       â””â”€â”€ constants.ts            # Shared constants
â”‚
â”œâ”€â”€ python/                         # Python Pipeline (existing)
â”‚   â”œâ”€â”€ main.py                     # Modified for CLI/API mode
â”‚   â”œâ”€â”€ api_bridge.py               # NEW: JSON API for Electron
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ models/
â”‚
â””â”€â”€ resources/                      # App resources
    â”œâ”€â”€ icons/                      # App icons
    â””â”€â”€ python/                     # Bundled Python (optional)
```

### Component Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MAIN WINDOW                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                â”‚                                                  â”‚
â”‚   SIDEBAR      â”‚              MAIN CONTENT AREA                   â”‚
â”‚                â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ğŸ  Home â”‚  â”‚  â”‚                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚           DYNAMIC PAGE CONTENT              â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚                                            â”‚ â”‚
â”‚  â”‚ ğŸ“Š Data  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚                                      â”‚  â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚     Based on selected navigation     â”‚  â”‚ â”‚
â”‚  â”‚ âš™ï¸ Pipelineâ”‚ â”‚  â”‚  â”‚                                      â”‚  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚  - Home: Quick actions + status      â”‚  â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚  - Data: Upload + preview            â”‚  â”‚ â”‚
â”‚  â”‚ ğŸ“ˆ Chartsâ”‚  â”‚  â”‚  â”‚  - Pipeline: Phase config + run      â”‚  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚  - Charts: Interactive visualizationsâ”‚  â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”‚  - Results: Summaries + exports      â”‚  â”‚ â”‚
â”‚  â”‚ ğŸ“„ Resultsâ”‚ â”‚  â”‚  â”‚  - Settings: LLM + app config        â”‚  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â”‚                                      â”‚  â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚ âš¡ Settingsâ”‚ â”‚  â”‚                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LLM: âœ…  â”‚  â”‚  â”‚             STATUS BAR                     â”‚ â”‚
â”‚  â”‚Ollama OK â”‚  â”‚  â”‚  Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80%  | Memory: 4.2GB â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Python-Electron Communication Protocol

### IPC Message Protocol

```typescript
// TypeScript Interface
interface PipelineCommand {
  action: 'run_phase' | 'run_all' | 'stop' | 'get_status' | 'configure';
  phase?: number;
  config?: PhaseConfig;
  dataset?: string;
}

interface PipelineResponse {
  success: boolean;
  phase?: number;
  status: 'running' | 'completed' | 'error' | 'stopped';
  progress?: number;
  data?: any;
  error?: string;
}
```

### Python API Bridge (New File)

```python
# python/api_bridge.py
"""
JSON API Bridge for Electron Communication
==========================================
Provides a JSON-based interface for the pipeline.
"""

import sys
import json
from typing import Dict, Any
from core import (
    ProcesadorBasico,
    AnalizadorSentimientos,
    AnalizadorSubjetividad,
    ClasificadorCategorias,
    AnalizadorJerarquicoTopicos,
    ResumidorInteligente,
    GeneradorVisualizaciones
)

class PipelineAPI:
    """JSON API for the analysis pipeline."""
    
    def __init__(self):
        self.phases = {
            1: ('Procesamiento BÃ¡sico', ProcesadorBasico),
            2: ('AnÃ¡lisis de Sentimientos', AnalizadorSentimientos),
            3: ('AnÃ¡lisis de Subjetividad', AnalizadorSubjetividad),
            4: ('ClasificaciÃ³n de CategorÃ­as', ClasificadorCategorias),
            5: ('AnÃ¡lisis JerÃ¡rquico de TÃ³picos', AnalizadorJerarquicoTopicos),
            6: ('Resumen Inteligente', ResumidorInteligente),
            7: ('GeneraciÃ³n de Visualizaciones', GeneradorVisualizaciones),
        }
    
    def execute(self, command: Dict[str, Any]) -> Dict[str, Any]:
        """Execute a pipeline command and return JSON response."""
        action = command.get('action')
        
        if action == 'run_phase':
            return self._run_phase(command['phase'], command.get('config', {}))
        elif action == 'run_all':
            return self._run_all(command.get('config', {}))
        elif action == 'get_status':
            return self._get_status()
        elif action == 'validate_dataset':
            return self._validate_dataset(command['path'])
        else:
            return {'success': False, 'error': f'Unknown action: {action}'}
    
    def _run_phase(self, phase: int, config: Dict) -> Dict:
        """Run a specific pipeline phase."""
        # Implementation with progress callbacks
        pass

# Main entry for subprocess communication
if __name__ == '__main__':
    api = PipelineAPI()
    for line in sys.stdin:
        command = json.loads(line)
        result = api.execute(command)
        print(json.dumps(result), flush=True)
```

---

## ğŸ¨ UI/UX Design Specifications

### Design System

| Element | Specification |
|---------|--------------|
| **Color Palette** | Blue primary (#3B82F6), Green success, Amber warning, Red error |
| **Typography** | Inter for UI, JetBrains Mono for code/data |
| **Spacing** | 4px base unit (Tailwind default) |
| **Border Radius** | 8px default, 12px for cards |
| **Shadows** | Subtle elevation system |
| **Dark Mode** | Full support with system preference |

### Key Screens Mockup Descriptions

#### 1. Home Dashboard
- Quick status overview (LLM status, last analysis date)
- Recent projects/datasets list
- Quick action buttons (New Analysis, Open Results)
- System health indicators

#### 2. Data Management
- Drag-and-drop CSV upload zone
- Data preview table with pagination
- Column validation status
- Data statistics summary

#### 3. Pipeline Configuration
- Visual phase cards (7 phases)
- Toggle switches for each phase
- Phase-specific configuration panels
- Run button with estimated time

#### 4. Pipeline Execution
- Real-time progress indicator per phase
- Console output log (expandable)
- Cancel/Pause controls
- Memory/CPU usage display

#### 5. Visualizations Gallery
- Grid of generated charts
- Filter by category (Sentiment, Topics, etc.)
- Click to expand/interact
- Export options (PNG, PDF, SVG)

#### 6. Results & Summaries
- AI-generated summaries display
- Markdown rendering for reports
- Export to Word/PDF
- Share functionality

#### 7. Settings
- LLM configuration (Mode, Model, API Key)
- Ollama management (Install, Pull models, Status)
- App preferences (Theme, Language, Paths)
- Cache management

---

## ğŸ”Œ External Integrations

### Ollama Integration

```typescript
// Electron Main Process - Ollama Manager
class OllamaManager {
  private baseUrl: string = 'http://localhost:11434';
  
  async checkStatus(): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseUrl}/api/tags`);
      return response.ok;
    } catch {
      return false;
    }
  }
  
  async listModels(): Promise<string[]> {
    const response = await fetch(`${this.baseUrl}/api/tags`);
    const data = await response.json();
    return data.models.map(m => m.name);
  }
  
  async pullModel(name: string, onProgress: (p: number) => void): Promise<void> {
    // Stream progress updates
  }
}
```

### OpenAI API Integration

- API key stored securely with electron-store
- Key validation on save
- Usage tracking (optional)
- Error handling with user-friendly messages

---

## ğŸ’¾ Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV File  â”‚â”€â”€â”€â”€â–¶â”‚  Validation â”‚â”€â”€â”€â”€â–¶â”‚   Storage   â”‚
â”‚   (Input)   â”‚     â”‚   & Parse   â”‚     â”‚  (App Data) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PIPELINE EXECUTION                  â”‚
â”‚  Phase 1 â”€â”€â–¶ Phase 2 â”€â”€â–¶ ... â”€â”€â–¶ Phase 7           â”‚
â”‚     â”‚          â”‚                    â”‚               â”‚
â”‚     â–¼          â–¼                    â–¼               â”‚
â”‚  Progress   Progress            Progress            â”‚
â”‚  Updates    Updates             Updates             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUTS                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Charts  â”‚ â”‚ Summariesâ”‚ â”‚  Dataset â”‚            â”‚
â”‚  â”‚  (PNG)   â”‚ â”‚  (JSON)  â”‚ â”‚  (CSV)   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Distribution Strategy

### Bundling Options

| Option | Bundle Size | Pros | Cons |
|--------|-------------|------|------|
| **Bundled Python** | ~500MB-1GB | No Python install needed | Larger download |
| **System Python** | ~150MB | Smaller app | User must install Python |
| **Hybrid** | ~200MB | Downloads Python on first run | Initial setup time |

### Recommended: Bundled Python with PyInstaller

```bash
# Create standalone Python bundle
pyinstaller --onedir --add-data "models:models" api_bridge.py

# Bundle with Electron
electron-builder --config electron-builder.yml
```

### Platform Builds

| Platform | Format | Notes |
|----------|--------|-------|
| Windows | .exe (NSIS) | Most common |
| macOS | .dmg | Code signing required |
| Linux | .AppImage, .deb | Universal + Debian |

---

## ğŸš€ First-Run Setup & Onboarding

### Overview

The application must provide a **seamless "all-in-one" installation experience**. When a user installs the app, all dependencies, models, and configurations should be handled automatically with minimal user intervention. The user should only need to choose their LLM provider preference.

### First-Run Setup Wizard Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       FIRST RUN WIZARD                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STEP 1: Welcome & System Requirements Check                    â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  âœ“ Checking bundled Python runtime...                    [OK]  â”‚ â”‚
â”‚  â”‚  âœ“ Verifying disk space (5GB required)...                [OK]  â”‚ â”‚
â”‚  â”‚  âœ“ Detecting GPU availability...                    [CUDA 12]  â”‚ â”‚
â”‚  â”‚  âœ“ Checking system memory (8GB+ recommended)...     [16GB OK]  â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚                              [Continue â†’]                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                 â”‚                                    â”‚
â”‚                                 â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STEP 2: Choose Your LLM Provider                               â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚  â”‚  ğŸ–¥ï¸ LOCAL LLM        â”‚    â”‚  â˜ï¸ OPENAI API       â”‚         â”‚ â”‚
â”‚  â”‚  â”‚     (Ollama)         â”‚    â”‚                      â”‚         â”‚ â”‚
â”‚  â”‚  â”‚                      â”‚    â”‚                      â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Free & Private    â”‚    â”‚  â€¢ No GPU Required   â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Requires ~4GB RAM â”‚    â”‚  â€¢ Pay per use       â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ ~2GB download     â”‚    â”‚  â€¢ Faster setup      â”‚         â”‚ â”‚
â”‚  â”‚  â”‚                      â”‚    â”‚                      â”‚         â”‚ â”‚
â”‚  â”‚  â”‚    [Select Local]    â”‚    â”‚   [Select OpenAI]    â”‚         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                 â”‚                                    â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚               â–¼                                   â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STEP 2A: Ollama Setup   â”‚      â”‚ STEP 2B: OpenAI Setup       â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                         â”‚      â”‚                             â”‚   â”‚
â”‚  â”‚ â–¡ Installing Ollama...  â”‚      â”‚ Enter your OpenAI API Key:  â”‚   â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 67%      â”‚      â”‚                             â”‚   â”‚
â”‚  â”‚                         â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚ â–¡ Downloading llama3.2  â”‚      â”‚ â”‚ sk-...                  â”‚ â”‚   â”‚
â”‚  â”‚   (2.1 GB remaining)    â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 52%      â”‚      â”‚                             â”‚   â”‚
â”‚  â”‚                         â”‚      â”‚ âœ“ Key validated             â”‚   â”‚
â”‚  â”‚ ETA: ~5 minutes         â”‚      â”‚                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â”‚                                    â”‚
â”‚                                 â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STEP 3: Downloading AI Models                                  â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  âœ“ BERT Sentiment Model (nlptown/bert-base)         [420 MB]  â”‚ â”‚
â”‚  â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%      â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  âœ“ Sentence Transformers (all-MiniLM-L6-v2)         [80 MB]   â”‚ â”‚
â”‚  â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%      â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  â†’ Subjectivity Model (custom fine-tuned)           [440 MB]  â”‚ â”‚
â”‚  â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 45%       â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  â—‹ Category Classifier (custom multi-label)         [440 MB]  â”‚ â”‚
â”‚  â”‚    Waiting...                                                  â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  Total Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 61%       â”‚ â”‚
â”‚  â”‚  Downloaded: 940 MB / 1.5 GB  |  ETA: ~3 minutes               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                 â”‚                                    â”‚
â”‚                                 â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ STEP 4: Setup Complete! ğŸ‰                                     â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚     âœ… All components installed successfully!                  â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚     â€¢ Python Runtime: Bundled v3.11                           â”‚ â”‚
â”‚  â”‚     â€¢ LLM Provider: Ollama (llama3.2)                         â”‚ â”‚
â”‚  â”‚     â€¢ AI Models: 4/4 ready                                    â”‚ â”‚
â”‚  â”‚     â€¢ Disk Used: 4.2 GB                                       â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  ğŸ“ Upload your first CSV to begin analysis!             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚         [Drag & Drop CSV or Click to Browse]             â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚                    [Start Analyzing â†’]                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Installation Components Breakdown

#### What Gets Installed Automatically

| Component | Size | Install Method | When |
|-----------|------|----------------|------|
| **Electron App** | ~150 MB | Bundled in installer | During install |
| **Python Runtime** | ~100 MB | Bundled via PyInstaller | During install |
| **Python Dependencies** | ~800 MB | Bundled in Python package | During install |
| **Ollama** (if selected) | ~500 MB | Auto-download + install | First-run wizard |
| **Ollama LLM Model** | ~2 GB | `ollama pull` via API | First-run wizard |
| **HuggingFace Models** | ~1 GB | `transformers` auto-download | First-run wizard |
| **Custom Fine-tuned Models** | ~900 MB | Bundled or download | During install / First-run |

**Total Installation Size:** ~4-5 GB (depending on LLM choice)

### Installer Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INSTALLER PACKAGE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  ai-tourism-analyzer-setup.exe (Windows)                        â”‚
â”‚  ai-tourism-analyzer.dmg (macOS)                                â”‚
â”‚  ai-tourism-analyzer.AppImage (Linux)                           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  BUNDLED CONTENTS                          â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  /app                                                      â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ electron/              # Electron runtime             â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ resources/                                            â”‚  â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ app.asar          # React frontend (compiled)    â”‚  â”‚
â”‚  â”‚  â”‚   â””â”€â”€ python/           # Bundled Python environment   â”‚  â”‚
â”‚  â”‚  â”‚       â”œâ”€â”€ python.exe    # Python interpreter           â”‚  â”‚
â”‚  â”‚  â”‚       â”œâ”€â”€ Lib/          # Python packages (torch, etc) â”‚  â”‚
â”‚  â”‚  â”‚       â””â”€â”€ pipeline/     # Pipeline code                â”‚  â”‚
â”‚  â”‚  â”‚           â”œâ”€â”€ core/                                     â”‚  â”‚
â”‚  â”‚  â”‚           â”œâ”€â”€ config/                                   â”‚  â”‚
â”‚  â”‚  â”‚           â””â”€â”€ api_bridge.py                            â”‚  â”‚
â”‚  â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚  â””â”€â”€ models/               # Pre-bundled custom models     â”‚  â”‚
â”‚  â”‚      â”œâ”€â”€ subjectivity_task/                               â”‚  â”‚
â”‚  â”‚      â””â”€â”€ multilabel_task/                                 â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              DOWNLOADED ON FIRST RUN                       â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  ~/.ai-tourism-analyzer/                                  â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ huggingface_cache/    # HuggingFace model cache      â”‚  â”‚
â”‚  â”‚  â”‚   â”œâ”€â”€ nlptown--bert-base-multilingual-uncased-sentimentâ”‚  â”‚
â”‚  â”‚  â”‚   â””â”€â”€ sentence-transformers--all-MiniLM-L6-v2          â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ ollama/ (if local LLM) # Ollama installation         â”‚  â”‚
â”‚  â”‚  â”‚   â””â”€â”€ models/                                          â”‚  â”‚
â”‚  â”‚  â”‚       â””â”€â”€ llama3.2/                                    â”‚  â”‚
â”‚  â”‚  â”œâ”€â”€ projects/             # User analysis projects        â”‚  â”‚
â”‚  â”‚  â””â”€â”€ config.json           # User preferences              â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SetupManager Implementation

```typescript
// src/main/setup/SetupManager.ts

interface SetupState {
  isFirstRun: boolean;
  setupComplete: boolean;
  currentStep: SetupStep;
  llmProvider: 'ollama' | 'openai' | null;
  modelsDownloaded: ModelStatus[];
  errors: SetupError[];
}

interface ModelStatus {
  name: string;
  size: number;
  downloaded: boolean;
  progress: number;
}

type SetupStep = 
  | 'welcome'
  | 'system-check'
  | 'llm-selection'
  | 'ollama-install'
  | 'openai-config'
  | 'model-download'
  | 'complete';

class SetupManager {
  private state: SetupState;
  private store: ElectronStore;

  constructor() {
    this.store = new Store();
    this.state = this.loadState();
  }

  async isFirstRun(): Promise<boolean> {
    return !this.store.get('setup.complete', false);
  }

  async runSystemCheck(): Promise<SystemCheckResult> {
    return {
      pythonRuntime: await this.checkPythonRuntime(),
      diskSpace: await this.checkDiskSpace(5 * 1024 * 1024 * 1024), // 5GB
      memory: await this.checkSystemMemory(),
      gpu: await this.detectGPU(),
    };
  }

  async installOllama(onProgress: ProgressCallback): Promise<void> {
    const platform = process.platform;
    
    if (platform === 'darwin') {
      // macOS: Download and run installer
      await this.downloadFile(
        'https://ollama.com/download/Ollama-darwin.zip',
        onProgress
      );
      await this.extractAndInstall();
    } else if (platform === 'win32') {
      // Windows: Download and run installer
      await this.downloadFile(
        'https://ollama.com/download/OllamaSetup.exe',
        onProgress
      );
      await this.runInstaller();
    } else {
      // Linux: Use install script
      await this.runCommand('curl -fsSL https://ollama.com/install.sh | sh');
    }
    
    // Start Ollama service
    await this.startOllamaService();
  }

  async pullOllamaModel(
    modelName: string, 
    onProgress: ProgressCallback
  ): Promise<void> {
    const response = await fetch('http://localhost:11434/api/pull', {
      method: 'POST',
      body: JSON.stringify({ name: modelName, stream: true }),
    });

    const reader = response.body?.getReader();
    while (reader) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const data = JSON.parse(new TextDecoder().decode(value));
      if (data.total && data.completed) {
        onProgress(data.completed / data.total * 100);
      }
    }
  }

  async downloadHuggingFaceModels(onProgress: ProgressCallback): Promise<void> {
    const models = [
      { name: 'nlptown/bert-base-multilingual-uncased-sentiment', size: 420 },
      { name: 'sentence-transformers/all-MiniLM-L6-v2', size: 80 },
    ];

    // Trigger Python to download models with progress tracking
    await this.pythonBridge.execute({
      action: 'download_models',
      models: models.map(m => m.name),
      onProgress: (model: string, progress: number) => {
        onProgress({ model, progress });
      }
    });
  }

  async validateOpenAIKey(apiKey: string): Promise<boolean> {
    try {
      const response = await fetch('https://api.openai.com/v1/models', {
        headers: { 'Authorization': `Bearer ${apiKey}` }
      });
      return response.ok;
    } catch {
      return false;
    }
  }

  async markSetupComplete(): Promise<void> {
    this.store.set('setup.complete', true);
    this.store.set('setup.completedAt', new Date().toISOString());
  }
}
```

### Python Model Downloader

```python
# python/setup/model_downloader.py
"""
Model Downloader for First-Run Setup
=====================================
Downloads and caches all required ML models with progress tracking.
"""

import os
import sys
import json
from pathlib import Path
from typing import Callable, Dict, List

# Ensure HuggingFace cache is in app directory
os.environ['HF_HOME'] = str(Path.home() / '.ai-tourism-analyzer' / 'huggingface_cache')
os.environ['TRANSFORMERS_CACHE'] = os.environ['HF_HOME']

class ModelDownloader:
    """Manages ML model downloads with progress tracking."""
    
    REQUIRED_MODELS = {
        'sentiment': {
            'name': 'nlptown/bert-base-multilingual-uncased-sentiment',
            'size_mb': 420,
            'type': 'transformers'
        },
        'embeddings': {
            'name': 'sentence-transformers/all-MiniLM-L6-v2',
            'size_mb': 80,
            'type': 'sentence-transformers'
        },
    }
    
    BUNDLED_MODELS = {
        'subjectivity': {
            'path': 'models/subjectivity_task',
            'size_mb': 440,
        },
        'categories': {
            'path': 'models/multilabel_task', 
            'size_mb': 440,
        },
    }

    def __init__(self, progress_callback: Callable[[str, float], None] = None):
        self.progress_callback = progress_callback or (lambda *args: None)
        self.cache_dir = Path.home() / '.ai-tourism-analyzer' / 'huggingface_cache'
        self.cache_dir.mkdir(parents=True, exist_ok=True)

    def check_models_status(self) -> Dict[str, bool]:
        """Check which models are already downloaded."""
        status = {}
        
        for key, model_info in self.REQUIRED_MODELS.items():
            status[key] = self._is_model_cached(model_info['name'])
        
        for key, model_info in self.BUNDLED_MODELS.items():
            status[key] = Path(model_info['path']).exists()
        
        return status

    def download_all_models(self) -> Dict[str, bool]:
        """Download all required models with progress tracking."""
        results = {}
        
        # Download HuggingFace models
        for key, model_info in self.REQUIRED_MODELS.items():
            self.progress_callback(model_info['name'], 0)
            
            try:
                if model_info['type'] == 'transformers':
                    from transformers import AutoModel, AutoTokenizer
                    AutoTokenizer.from_pretrained(model_info['name'])
                    AutoModel.from_pretrained(model_info['name'])
                    
                elif model_info['type'] == 'sentence-transformers':
                    from sentence_transformers import SentenceTransformer
                    SentenceTransformer(model_info['name'])
                
                self.progress_callback(model_info['name'], 100)
                results[key] = True
                
            except Exception as e:
                self.progress_callback(model_info['name'], -1)  # Error
                results[key] = False
                print(json.dumps({'error': str(e), 'model': key}), file=sys.stderr)
        
        # Verify bundled models exist
        for key, model_info in self.BUNDLED_MODELS.items():
            results[key] = Path(model_info['path']).exists()
        
        return results

    def _is_model_cached(self, model_name: str) -> bool:
        """Check if a model is already in the cache."""
        from huggingface_hub import scan_cache_dir
        try:
            cache_info = scan_cache_dir(self.cache_dir)
            cached_repos = [repo.repo_id for repo in cache_info.repos]
            return model_name in cached_repos
        except Exception:
            return False

    def get_total_download_size(self) -> int:
        """Calculate total download size in MB."""
        status = self.check_models_status()
        total = 0
        
        for key, model_info in self.REQUIRED_MODELS.items():
            if not status.get(key, False):
                total += model_info['size_mb']
        
        return total


# CLI interface for Electron bridge
if __name__ == '__main__':
    def progress_handler(model: str, progress: float):
        print(json.dumps({
            'type': 'progress',
            'model': model,
            'progress': progress
        }), flush=True)
    
    downloader = ModelDownloader(progress_callback=progress_handler)
    
    command = json.loads(sys.stdin.readline())
    
    if command['action'] == 'check_status':
        result = downloader.check_models_status()
        print(json.dumps({'status': result}), flush=True)
        
    elif command['action'] == 'download_all':
        result = downloader.download_all_models()
        print(json.dumps({'success': all(result.values()), 'details': result}), flush=True)
        
    elif command['action'] == 'get_download_size':
        size = downloader.get_total_download_size()
        print(json.dumps({'size_mb': size}), flush=True)
```

### Ollama Auto-Installer

```typescript
// src/main/setup/OllamaInstaller.ts

import { spawn, exec } from 'child_process';
import { download } from 'electron-dl';
import { app } from 'electron';
import path from 'path';
import fs from 'fs';

interface InstallProgress {
  stage: 'downloading' | 'installing' | 'starting' | 'pulling-model';
  progress: number;
  message: string;
}

class OllamaInstaller {
  private downloadUrl: Record<NodeJS.Platform, string> = {
    darwin: 'https://ollama.com/download/Ollama-darwin.zip',
    win32: 'https://ollama.com/download/OllamaSetup.exe',
    linux: '', // Uses install script
  };

  async isOllamaInstalled(): Promise<boolean> {
    return new Promise((resolve) => {
      exec('ollama --version', (error) => {
        resolve(!error);
      });
    });
  }

  async isOllamaRunning(): Promise<boolean> {
    try {
      const response = await fetch('http://localhost:11434/api/tags');
      return response.ok;
    } catch {
      return false;
    }
  }

  async install(onProgress: (p: InstallProgress) => void): Promise<void> {
    const platform = process.platform;

    if (await this.isOllamaInstalled()) {
      onProgress({ stage: 'installing', progress: 100, message: 'Ollama already installed' });
      await this.ensureRunning();
      return;
    }

    if (platform === 'linux') {
      await this.installLinux(onProgress);
    } else if (platform === 'darwin') {
      await this.installMacOS(onProgress);
    } else if (platform === 'win32') {
      await this.installWindows(onProgress);
    }

    // Start service
    onProgress({ stage: 'starting', progress: 0, message: 'Starting Ollama service...' });
    await this.ensureRunning();
    onProgress({ stage: 'starting', progress: 100, message: 'Ollama service started' });
  }

  private async installLinux(onProgress: (p: InstallProgress) => void): Promise<void> {
    return new Promise((resolve, reject) => {
      onProgress({ stage: 'installing', progress: 0, message: 'Running install script...' });
      
      const install = spawn('sh', ['-c', 'curl -fsSL https://ollama.com/install.sh | sh']);
      
      install.on('close', (code) => {
        if (code === 0) {
          onProgress({ stage: 'installing', progress: 100, message: 'Installation complete' });
          resolve();
        } else {
          reject(new Error(`Installation failed with code ${code}`));
        }
      });
    });
  }

  private async installWindows(onProgress: (p: InstallProgress) => void): Promise<void> {
    const installerPath = path.join(app.getPath('temp'), 'OllamaSetup.exe');
    
    // Download installer
    onProgress({ stage: 'downloading', progress: 0, message: 'Downloading Ollama...' });
    
    await download(BrowserWindow.getFocusedWindow()!, this.downloadUrl.win32, {
      directory: app.getPath('temp'),
      filename: 'OllamaSetup.exe',
      onProgress: (p) => {
        onProgress({ 
          stage: 'downloading', 
          progress: p.percent * 100, 
          message: `Downloading... ${Math.round(p.percent * 100)}%` 
        });
      }
    });

    // Run installer silently
    onProgress({ stage: 'installing', progress: 0, message: 'Installing Ollama...' });
    
    return new Promise((resolve, reject) => {
      exec(`"${installerPath}" /S`, (error) => {
        if (error) reject(error);
        else {
          onProgress({ stage: 'installing', progress: 100, message: 'Installation complete' });
          resolve();
        }
      });
    });
  }

  async pullModel(
    modelName: string = 'llama3.2',
    onProgress: (p: InstallProgress) => void
  ): Promise<void> {
    onProgress({ 
      stage: 'pulling-model', 
      progress: 0, 
      message: `Downloading ${modelName}...` 
    });

    const response = await fetch('http://localhost:11434/api/pull', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ name: modelName, stream: true }),
    });

    const reader = response.body?.getReader();
    const decoder = new TextDecoder();

    while (reader) {
      const { done, value } = await reader.read();
      if (done) break;

      const lines = decoder.decode(value).split('\n').filter(Boolean);
      
      for (const line of lines) {
        try {
          const data = JSON.parse(line);
          if (data.total && data.completed) {
            const progress = (data.completed / data.total) * 100;
            onProgress({
              stage: 'pulling-model',
              progress,
              message: `Downloading ${modelName}... ${Math.round(progress)}%`
            });
          }
        } catch {}
      }
    }

    onProgress({ 
      stage: 'pulling-model', 
      progress: 100, 
      message: `${modelName} ready!` 
    });
  }

  private async ensureRunning(): Promise<void> {
    if (await this.isOllamaRunning()) return;

    // Start Ollama
    if (process.platform === 'win32') {
      spawn('ollama', ['serve'], { detached: true, stdio: 'ignore' }).unref();
    } else {
      spawn('ollama', ['serve'], { detached: true, stdio: 'ignore' }).unref();
    }

    // Wait for it to be ready
    for (let i = 0; i < 30; i++) {
      await new Promise(r => setTimeout(r, 1000));
      if (await this.isOllamaRunning()) return;
    }

    throw new Error('Failed to start Ollama service');
  }
}

export default OllamaInstaller;
```

### Setup Wizard React Component

```tsx
// src/renderer/components/setup/SetupWizard.tsx

import React, { useState, useEffect } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { CheckCircle, Circle, Loader, AlertCircle } from 'lucide-react';

type Step = 'welcome' | 'system-check' | 'llm-choice' | 'llm-setup' | 'models' | 'complete';

interface SetupWizardProps {
  onComplete: () => void;
}

export function SetupWizard({ onComplete }: SetupWizardProps) {
  const [currentStep, setCurrentStep] = useState<Step>('welcome');
  const [llmChoice, setLlmChoice] = useState<'ollama' | 'openai' | null>(null);
  const [progress, setProgress] = useState<Record<string, number>>({});
  const [errors, setErrors] = useState<string[]>([]);

  const steps: Step[] = ['welcome', 'system-check', 'llm-choice', 'llm-setup', 'models', 'complete'];

  // ... component implementation with step-by-step UI
  // Each step renders appropriate content and handles progression
}
```

### Error Handling & Recovery

| Scenario | Detection | Recovery Action |
|----------|-----------|-----------------|
| Insufficient disk space | Pre-check | Show required space, suggest cleanup |
| Download interrupted | Progress stalls | Resume download, offer retry |
| Ollama install fails | Exit code â‰  0 | Manual install instructions + fallback to OpenAI |
| Model download fails | HTTP error | Retry with exponential backoff |
| OpenAI key invalid | API 401 response | Re-prompt for correct key |
| GPU not available | CUDA check fails | Warn user, continue with CPU |

### Offline Mode Considerations

For enterprise/air-gapped environments:

1. **Offline Installer Package**: 
   - Include all models pre-bundled (~5GB total installer)
   - Flag: `--offline` or detect no internet

2. **Model Pre-loading**:
   - Ship HuggingFace models in installer
   - Skip download step if models exist

3. **OpenAI-Only Mode**:
   - If user has no internet during setup, defer LLM choice
   - Allow configuration later via Settings

---

## âš¡ Performance Considerations

### Memory Management

- Lazy load BERT models (only when phase runs)
- Unload models after phase completion
- Monitor system RAM and warn users
- Implement worker threads for heavy processing

### Startup Optimization

- Show splash screen during load
- Lazy load React components
- Cache Python environment check
- Background initialization

### GPU Utilization

- Detect CUDA availability
- Toggle GPU usage in settings
- Display GPU memory usage
- Fallback to CPU gracefully

---

## ğŸ” Security Considerations

| Concern | Mitigation |
|---------|------------|
| API Key Storage | Use electron-store with encryption |
| File Access | Use Electron's dialog APIs, no arbitrary paths |
| Python Execution | Sanitize all inputs, use subprocess safely |
| Updates | Signed releases, HTTPS update server |

---

## ğŸ“Š Comparison with Alternatives

| Feature | Electron | Tauri | PyQt/PySide | Neutralino |
|---------|----------|-------|-------------|------------|
| **Team JS Experience** | âœ… Perfect | âœ… Good | âŒ Python | âš ï¸ Limited |
| **App Size** | âš ï¸ 150MB+ | âœ… 10MB | âš ï¸ 100MB | âœ… 5MB |
| **Python Integration** | âœ… Easy | âš ï¸ Moderate | âœ… Native | âš ï¸ Hard |
| **Ecosystem** | âœ… Rich | âš ï¸ Growing | âœ… Mature | âŒ Limited |
| **Cross-platform** | âœ… Excellent | âœ… Excellent | âœ… Good | âœ… Good |
| **Maintenance** | âœ… Active | âœ… Active | âœ… Active | âš ï¸ Smaller |

**Verdict:** Given team experience with JavaScript and that app size is not a concern, **Electron is the optimal choice**.

---

## âœ… Feasibility Summary

| Aspect | Assessment | Notes |
|--------|------------|-------|
| **Technical Feasibility** | âœ… High | Clean modular Python code |
| **Team Skill Match** | âœ… Excellent | JavaScript experience |
| **Pipeline Reuse** | âœ… 100% | All phases work as-is |
| **LLM Integration** | âœ… Supported | Both Ollama and OpenAI |
| **Visualization** | âœ… Enhanced | Interactive web charts |
| **Distribution** | âœ… Feasible | Electron builder ecosystem |
| **Maintenance** | âœ… Good | Separate Python/JS concerns |
| **First-Run Setup** | âœ… Defined | Wizard handles all dependencies |
| **Model Management** | âœ… Automated | Auto-download with progress |
| **Ollama Installation** | âœ… Automated | Cross-platform auto-install |

---

## ğŸ¯ Conclusion

The desktop application is **fully feasible** with the proposed Electron + React + Python architecture. The existing pipeline code requires minimal modification, and the modular structure enables a clean separation between the UI layer (Electron/React) and the processing layer (Python).

**Key Success Factors:**
1. âœ… Existing code is modular and well-structured
2. âœ… Team has JavaScript experience
3. âœ… No backend server required
4. âœ… LLM options (local/API) are already implemented
5. âœ… Visualization outputs are display-ready

**Next Step:** See [DESKTOP_APP_IMPLEMENTATION_PLAN.md](./DESKTOP_APP_IMPLEMENTATION_PLAN.md) for the detailed implementation roadmap.
