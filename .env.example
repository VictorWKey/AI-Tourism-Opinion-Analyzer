# ===========================================
# TourlyAI — Environment Variables
# ===========================================
# Copy this file to .env and fill in the values.
# Never commit .env to version control.

# ── Sentry Error Reporting ──────────────────
# Get your DSN from https://sentry.io → Project Settings → Client Keys (DSN)
# DSNs are safe to share — they only allow sending events, not reading them.
SENTRY_DSN=
VITE_SENTRY_DSN=

# ── LLM Configuration ──────────────────────
# Mode: 'api' (OpenAI), 'local' (Ollama), or 'none'
LLM_MODE=local

# OpenAI API (only required when LLM_MODE=api)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Ollama (only required when LLM_MODE=local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# LLM temperature (0 = deterministic, 1 = creative)
LLM_TEMPERATURE=0

# ── Output Directory ───────────────────────
# Override the default output directory for pipeline results.
# Leave empty to use the default (python/data/).
OUTPUT_DIR=
